Speaker 1: 为什么你做这件事情比大部分人都早？你觉得是为什么？

Speaker 2: 我觉得有幸运的部分就是说我 PHD 做的第一个事情，其实就是基于语言模型去做 agent 的。你只有有个 different bat 你才能够超越之前的霸主，对吧？就是说我觉得如果 open a 一直做强化学习，那可能也很难超过 deep mind。我导师他是 GPT1 的第二作者，他当时对这个事情就有点怀疑。很有意思的一点是说，传统上大家认为发生的事情是，比如我大厂先做出来一个东西，然后创业公司就可以开始抄，对吧？比如说我做出来拆 GPT，那我可以去抄抄 GPT，或者去做一个类似的事情。但现在来看，似乎反过来事情也是可以成立的。

Speaker 1: 如果你成为了伯克希尔的 CEO，未来要拿出 500 亿美金 allocate 到 AGI 这个行业，你会怎么去 allocate 这笔钱？既能体现回报，也能体现对人类的贡献。

Speaker 2: 就是 back on 有 different super APP 的产品形态，有不同的交互方式。如果你不相信这一点的话，那这个世界就变得很灰暗。只有 open a 或者 a topic 有机会，但是如果你相信这一点的话，就会有很多新的机会。

Speaker 1: Hello， 大家好，欢迎收听张小军商业访谈录，我是小俊。这是一档由语言及世界工作室出品的深度访谈节目，我们希望和你一起从这里探索新世界。今天的嘉宾我们很开心邀请了 OpenAI 的研究员尧舜禹。2025 年 4 月尧舜禹发布了一篇很有名的博文，the second half， 宣告 AI 主线程的游戏已经进入了下半场。这之后我们与他进行了一场播客对谈。姚舜宇毕业于清华和普林斯顿大学，开始智能体的研究非常的早。在博士期间他意识到了语言可能是人类发明的最接近本质的工具，于是转向了语言智能体的研究，至今已经六年，他有许多有代表性的工作。我们的谈话从个体出发，共同探索由人组织 AI 人与机器的交互所抵达的这个世界，智能的边界，以及人类与机器的全景。

Speaker 1: 前不久我刚刚创立了一家新的内容工作室，语言及世界工作室。舜宇很意外的从另外一个角度帮我回答了我们工作室创立的初心。为什么我们相信语言是这个世界的本质奥秘？它的表达是语言是人为了实现泛化而发明出来的工具，这一点比其他东西更本质。

Speaker 1: Hello， 舜宇，先给听众朋友们打个招呼。

Speaker 2: 大家好，我叫尧舜禹，然后现在在 OpenAI 做 research。

Speaker 1: 今天我们嘉宾是 open ID 研究员尧舜宇，他的研究方向是 agent。最近刚刚写了一篇非常有名的博文 the second half，告诉大家 AI 的游戏已经进入了下半场。这次节目我们第一次也尝试有两位主持人，除了我还有大家也很熟悉的广觅广密，你也来给大家打个招呼。大家好，我是广密圣宇。我看了你的很多资料和你自己写的文字，我从你的文章语言里整体能读到一种反叛精神。所以我对你这个人很感兴趣，能不能先给大家做一个自我介绍，就是聊聊你的过往的经历。

Speaker 2: 你说反叛精神。

Speaker 1: 对。

Speaker 2: 这很有意思，因为我感觉我是个非常乖的学生。对我感觉从小到大就是按部就班的学习。我本科丛丛合肥考到清华，然后读姚班。要不然大家都会告诉你就是去去美国读 PHD，然后我就去美国读 PHD，然后我在普林斯顿读 PHD。然后通过 PHD 之后，感觉很自然的就是 OpenAI 是作为 research 最好的地方，然后就加入了 OpenAI，感觉就是我前 28 年的人生非常的乖。对，你是 15 到 19 在清华姚班。

Speaker 1: 19 到 24 在普林斯顿 24 年毕业季的 OpenAI 对吧？你之前学的应该不是 AI 就是在本科的时候你是怎么进入 AI 领域，然后继而又进入入了 agent 这个领域的对。

Speaker 2: 姚班的传统是偏理论计算机科学，但是可能我还是有反叛精神的。我当时觉得重要的问题可能已经被解决了。就是如果你去把一个比如图算法的复杂度从 N 的 2.83 次方降到 N 的 2.82 次方，这个事情已经对实际没有什么意义了。

Speaker 2: 然后我是 16 年的时候，在李健老师的一门课上面看到了一个 multi model to 的一个 demo。当时有一个就比如说你可以有一个 watch wag，有一个非常惊艳的 example，就是说一个国王的 ebel ding 减去一个慢的 100 0，再加上一个 queen 1 body，可以等于一个比如 women 的 ebel ding。这个事情我当时觉得非常神奇，然后这个事情可以做成，比如一个图片，一个比如说一个国王图片的 100 斤减去卖的 100 斤，再加上亏点，白天他能做做的非常，我当时觉得非常惊艳。对，但是当时其实清华或者起码姚犇没有什么做迪普特令的老师或者资源。

Speaker 2: 然后 18 年的时候，摇摆有一个传统，每个人都要去海外做一学期的 research。然后我去 FIT，跟的是吴家俊学长，然后从那里才真正开始系统性的做 deep lying。对然后当时我做的其实更多是 computer ation。但是我当时觉得好像微信你很难实现一个 general 的新的 AI。然后 intus 就是说感觉 language 是更更重要或者更 central 的一个东西。然后后来进了 PHD 之后就开始做 language。对那怎么进入。

Speaker 1: agent？

Speaker 2: 对这个事情其实我觉得也是有些机缘巧合。对，就是我的导师他之前有一些 research，就是说我怎么能在一个简单的语言游戏里面去做一个 agent。这个可能是 16 年 17 年时候的工作。就是说你用一个非常简陋的 RN 然后在一个非常小的文字游戏里面，你可以做一些这种动态的 interaction。比如说你学着学就知道，比如过桥之后就可以，比如说去河对岸，就类似于这样非常简单的事情。

Speaker 2: 我进入 grass school 之后，其实我我我我是被这个 computer vision 录取的。但是我当时已经不想做 computer vision 了，然后我就去找做 language 的人聊天，然后我就遇到我现在的导师卡 sic 我们就在 brainstorm 有什么 idea。然后我就说现在这个语言模型 GBT two 已经变得比你们当时要强很多了，那他现在玩游戏是不是也会变得更强？然后他说 maybe that's a good idea，然后我们就开始做这个事情了。然后从那开始就已经一直在做 agent，做了已经有六年了。对。

Speaker 1: 你觉得 agent 或者说 language 最吸引的是什么？

Speaker 2: 我觉得是他的 general ality。对，就是任何事情你都可以用语言去表示，或者说绝大多数事情你可以用语言去表示。我我觉得我觉得很吸引我的一点就是说我当时我就隐约约有 intuition，就是说你最终比如你要实现一个 AGI，当然当时大家没有人提 AGI，但如果你要去实现一个非常 general system，那你需要去 build 一个 agent。

Speaker 2: 当时我觉得如果回看 AI 的历史的话，从很久很久以前，从 noy s Simon 他们 1960 年代开始，其实大家一开始的想法就是想去做一个 agent。当时大家的这个野心非常 ambitious，吧？就是说我们想用一个 summers 去解决 vision，想用另一个 summer 去解决 language。然后我们把这些东西拼在一起，我们去做一个 agent 的，然后他就比人聪明了。包括你去看图灵一开始的想法，就是说大家都会想去很自然的想要去 build 一个人或者 build 一个 agent。但是这个事情太难了，所以我觉得逐渐的 AI 就变得非常碎片化，然后也大家研究的问题也越来越小，对吧？就是说有些人去研究我怎么去解决比如说 vision 的这一小部分问题，或者去解决 language 的这一小部分问题，或者更细一步就 translation 的这一小部分问题，最后就变得越来越细分，越来越 vertical。但是我觉得 15 年以后，实际上 skin law 诞生，包括很多 research breakthrough 诞生历史的大事。就是说我们应该从这种 vertical thinking 重新回到一个更 general 的 thinking，然后去试图并构建一个更更通用的系统对当你进入到。

Speaker 1: agent 系统做研究的时候，你意识到最重要的几个事情，就是当要你要把语言模型让它行动起来。

Speaker 2: 有有一些收获。我觉得我第一年最大的收获就是说要用 GPT，不要用 bert。然后这里解释一下，就可能现在已经很多人不知道什么是 bert 了，就是当时最火的语言，这个领域最火的模型叫做 bert。然后他的想法就是说我去学一个表示，就是说我有一句话，然后我可以通过某种方式学到这句话的一个表示。然后我可以通过这个表示做很多下游的任务。比如说去做一些比如说单选题，或者去做一些这种基于选择的任务。然后当时我觉得可能 95%的人在做 bert 然后可能只有 5%的人在做 GPT1。

Speaker 2: 这也是因为当时自然语言处理的主要的任务都是一些，比如我有一个我有一句话，然后这句话是积极的还是不积极的。比如说我很讨厌这个电影，这是一个负面的句子。就是做一些非常简单的这种事情，在这种事情上 bt 确实效果更好。

Speaker 2: 但是你会发现，如果你要做一个 agent，那你需要的不只是选择能力，而是去自由产生新的动作的能力。当然如果你在玩围棋或者你在玩视频游戏的话，你的选择是很有限的。比如你在玩这个马里奥兄弟，那他可能就上下左右，对吧？但是你如果去玩一个基于语言的游戏，那你的动作是自由的。比如说我在这个游戏里面，我可以用这个剑杀这个怪兽，或者我可以去第三个房间，或者我可以用我的金色的钥匙打开了第一个房间的门。这个事情是 bert 永远做不到的，所以我发现这个事情之后，我就再也没有用过 bert。

Speaker 2: 我觉得第二个 learning 就是说任务或者环境非常重要。就是当你有一个非常差的任务的时候，你永远不可能学到非常好的东西。从某种程度来说，就当时有很多人在做，现在来看很简单的任务，对吧？比如说这个句子是正面的还是负面的，或者说我怎么去判断，比如说 A 这句话能不能导致 B 这句话是不是成立。就现在当时这些任务看上去很难，但是其实现在看上去非常简单。我觉得就是首先你要找一个足够有挑战的任务，然后这个任务能够做出有本质的新的方法。然后实际上当时你想去做 agent 或者想做语言的 agent 没有什么选择，就是可能你只能去做。

Speaker 2: 比如这些文字游戏，比如说 zorc 是一个非常经典的文字游戏。就是说你在一个文字基于文字的世界里面，就有点像一个互动的脚本一样。就是说你可以去往上走，你可以去个人房间，你可以去做各种各样的事情。但是你会发现这个环境还有很多缺陷，就是说你能学到的东西是局限在这个环境里了，这个环境还是不够大。而且你如果要用 RL 去学这个环境的话，那就会像用 RL 学传统的视频游戏一样。就是说你可以把这个游戏打通关，但他对于其他任何的任务没有任何的迁移作用，对吧？你可以把围棋下特别好，但他对世界上任何其他事情没有任何价值。那我觉得就是可能我们需要一个更好的环境。

Speaker 1: 对你博士期间其实做了很多工作，而且很多知名度也很高。包括这种 language agent，有 react，有 reflection，还有思维，然后包括 digital automation，数字自动化等等等等。就是这些研究的跨度大吗？他们之间的共性问题是什么？你是怎么按着你的兴趣点一步一步的去做他们的延伸的？

Speaker 2: 我觉得从我的角度是一个非常自然的过程，就当我意识到环境有问题的时候，实际上我觉得我第一个比较重要的工作是就是 web shop。我觉得首先我们要解决一个环境问题，因为如果没有一个好的任务或者环境。我把这个游戏刷的再高，其实我觉得没有意义。其实 15 年的时候就有一个非常好的工作叫 word of bits。当时的 idea 就是说我们应该把电脑或者互联网作为一个环境，这个环境比比游戏更 exciting。对，但是当时由于各种技术的局限性，就这个东西没有做的特别好。

Speaker 2: 然后 21 年的时候就是我和导师在讨论，就是说现在可能是一个很自然的重新做这个事情的时候。当然当时我觉得技术还也还没有成熟，就是当时大多多数人还是在研究，比如说这个 A 能不能导致 B 或者翻译，或者我能不能从这个文章中回答问题。当时想去做互联网的 agent 的，还是我觉得技术还没有完全成熟。但是可能正因为技术没有成熟，所以是一个好的时候开始做的。然后做到 22 年，我们做的就是 web shop 这个 environment。然后 22 年的时候就是 GPD3，包括后来 chain salt 的出现，我觉得是带来了新的方法上的机会，然后我们做了 react。我现在还是觉得就是我可能我自己最喜欢的工作还是 react 之后的话就是基于这两个线，就是很自然的去做了更多的方法，还有 task。对我但我觉得可能我的研究一方面是怎么去做一些有价值的，然后更基于现实世界的任务和环境。另一方面就是说怎么去做些简单并且通用的方法。

Speaker 1: React 提出它有标志一个范式的变化吗？

Speaker 2: 我觉得这个事情需要可能比如十年后或者五年后再去看。很多时候一个东西刚提出的时候是很难看出来的，当时的学术圈还是不太能接受。就是说我去做一个 prompting，然后去去把它作为一个 research。就是传统意义上你需要去提出一些 fancy 的，就是你需要提出一些数学公式，你需要去训练一个模型，你需要去证明你做了很多理论或者做了很多工程上的事情。但是如果你只是去，比如说使用一个模型，感觉这个太软了。

Speaker 2: 不过我觉得从某种程度上来说，当时最有价值的事情就是去研究怎么去使用模型。因为如果你是想训练模型，那实际上你是落后 open a 或者落后这些公司好几年了，对吧？然后你做的事情很有可能几年前别人已经发现了。如果你想要做一些不一样的事情，那可能怎么去使用模型是更有价值的。

Speaker 1: 为什么你做这件事情比大部分人都早，你觉得是为什么？

Speaker 2: 我觉得有幸运的部分就是说我 PHD 做的第一个事情，其实就是基于语言模型去做 agent 的。然后这个事情我觉得他当时做的人很少，因为这个事情我觉得可能太难了，或者说不是一个被不是一个共识类的事情，就是当时共识类的事情就是说我去做这个问答，或者我去做翻译，或者我去做一些已经被这个社区接受的一些任务。我觉得我一直有这个非共识，就是说我想要去做做 agent。

Speaker 2: 然后另一个点就是说我我我一直想做简单并且通用的东西，就我不想做一个很复杂但是只能在一个领域奏效的东西。就比如说当时有很多人我去做，比如问答，我会设计很复杂的架构，然后把这些 retrial，就是说我怎么把这些上下文放到你的模型里面去做很多东西。但是你最后发现这个事情可能只能做一个任务。我觉得我一直还是想做简单又通用的东西。然后这个事情我觉得传统意义上是很难被接受的，因为大家已经习惯了就是说 AI 就是说你把问题不停的细分，然后你去做很多细分的这些方法。就是大家可能并没有想要去做一个很简单很通用的事情，或者认为这个事情是可能的。在比如说 20 年之前或者今天我们的。

Speaker 1: 话题是 A 正的和强化学习，这也是你现在的研究方向。我们很好奇你会怎么定义 agent. 

Speaker 2: 这是一个很好的问题。我觉得这个事情是基于你的 context，就是基于你的讨论的背景的对，就是从历史的角度来说，我觉得从自然语言处理的角度来说，A 真的是相对于比如说一个产生文章或者产生对话的系统而言，我能够去和外界进行交互。比如说使用计算器，或者使用互联网，或者使用这些兔。我觉得从自然语言处理的角度来说，agent 的其实就是我不仅能够产生新的文章或者新的思考，我还能够和外界进行交互。但是从 AI 的各更大的背景来说，就 A 这个是一个非常古老的概念。就是说任何你可以去做自我决策和环境交互，然后这个 optimize reward 就是让他的这个奖励变大的这样的系统就都是 agent。从这个角度来说，今天的 agent 这个词的含义可能更多的是说我怎么基于像语言模型这样大模型能够去做自我决策的这样的 agent 系统。而不是传统的比如说单纯基于规则或者基于在一个领域做强化学习所获得的这样的 agent。

Speaker 2: 因为 agent 这个词在不同的年代有很多不同的形式，对吧？你也可以说阿尔法狗是一个 A 你也可以说 vivo 是一个 agent，你可以说这个 robot 是一个 agent。我觉得这个词很很基于你的情境对你提出。

Speaker 1: 这个语言 agent，它和其他之前的传统的 agent 它的本质区别是什么呢？为什么语言 A 真的更本质呢？

Speaker 2: 我觉得本质区别是可以推理，因为推理才可以泛化。就举个简单的例子，就是我觉得我做 react 一个很强的 motivation。就是说我做完 com 就是我的第一个工作之后，就是我在思考一个事情，就是说为什么我可以一下子就去玩一个新的游戏。但是现在这些系统或者 AI 需要比如说几十万步，或者几万步，或者几百万步的训练，你才能去做这个事情。

Speaker 2: 然后我就发现好像是因为我可以思考，对吧？就是说我看到一个全新的环境，我会思考就是说这个灯是黑的那那可能有危险。然后那那基于这个常识可能会有怪兽，那那可能我现在最重要的事情是要点亮灯，然后基于之前的上下文，灯在我后面我应该先向后走。那那如果我没有这样的一个思考能力，我直接从这样一个复杂的语言直接去预测，我要去往后走。这个事情很难，就是没有推理是做不到的。所以我觉得最大的区别就是说语言模型提供了一个足够强的先验。这个先验使得你可以推理，而推理又可以在不同环境间泛化。

Speaker 1: 所以它核心是推理能力，进而能泛化。因为你研究 agent 的和智能体非常早，就是从你的视角，agent 它到底是一个什么样的演变历史，它是怎么一步步发展到今天的对。

Speaker 2: 我可以说一下我自己的理解，但是可能并不完整或者是有一些错误。我觉得最早的 AI 就是我们被叫称为 good old fashion 的 AI 或者说叫叫符号主义。其实想法就很简单，就是说我注重的是推理，然后我推理的方式就是说我是怎么想的，我就把这些规则设计出来，然后让让这个 AI 也这么做。就是说如果我的这个温度高于 30 度，那这个空调就应该降温。就是基于这样的规则的这样的 AI 然后这个事情其实是可以造出来很多最早的智能体了。对，就是包括最早的 robot，最早的比如证明数学定理的，包括很多其他的系统都是这样创造出来的。

Speaker 2: 但是很快，比如说 1980 年代，大家发现这个东西是有瓶颈的。就是你不管写多少规则，你还是很难概括，很难涵盖这个世界上所有可能发生的情况。当时就是符号主义也没有到极致。就是说我们要去做这专家系统或者做很多我们去找很多专家，我们把这个世界上所有可能的规则全部写下来。那我们是不是就有 AGL，或者说有一个非常通用的有用的系统。但是最后发现好像你不管写多少规则，还是有很多特殊情况你处理不了。而且你写的这些规则也只能在这一个任务上面管用，对吧？

Speaker 2: 比如说你写了一个怎么去诊断这个心脏病的这样一个系统，那你写了很多很多规则，但是你还是没有办法去涵盖所有可能出现的情况。因为人人是一个就是他他会说任何事情，你没有办法去 handle。然后你写了这样一个心脏病的系统，你没有办法去处理。比如说肺病，那那这个事情就导致了第一次 AI 的寒冬，对吧？

Speaker 2: 然后我们有的 news network 有了神经网络，然后我觉得第二波就是 A 正的兴起是 deep reinforcement learning，就是深度强化学习标志性的事件。就比如说 deep mind 去做这些视频游戏，去做阿法狗。然后包括我们有些 OpenAI 玩机器手或者 dota 或者这样的一些游戏。然后这个的核心就是说我有一个我有个可以无穷次玩的这样一个虚拟的环境，然后我有一个奖励，然后我有一个非常通用的网络架构，然后我就去像黑盒一样，就是去学怎么去把这个 reward 去 improve，然后他就变强，然后这个事情我觉得取得了很多成功，我觉得可能最有名的事情是阿尔法狗。

Speaker 2: 对，但是我觉得还是有同样的问题。就是说你去做任何一个环境，你需要去做很多环境 substitution 的工程。就是说我去做 dota 我需要做很多基于这个环境的，比如说害怕 primitive tuning 或者工程，或者很多其他东西。

Speaker 2: 但是可能最大的问题还是他没有办法泛化。你去学了一个围棋的 A 真的你没有办法去玩其他游戏。你去做你去学的任何一个环境，你没有办法去泛化到另一个环境。那这个事情肯定很不好，对吧？而且如果你的所有的 sop 的环境都是这些虚拟的环境，或者说可以无穷次玩的像游戏一样的环境。那你没有办法找到很好的真实世界的应用。

Speaker 2: 我觉得可能第三波的 agent 就是从大语言模型开始，我们发现他可以去做推理。然后基于推理，你实际上是去可以做一些新的环境。比如说 coding，比如说互联网，比如说各种各样的数字环境。然后这些数字环境有很大的特点，就是它大多数情况下是基于语言的，然后是需要推理的。

Speaker 2: 所以我觉得这一次 agent 主要的其实区别就是有两方面。一方面是方法上，我们使用语言模型，使用推理去构建了很多处理各种各样问题的这样 agent。但另一方面就是说 A 镇的环境也发生了一个进化。就是从最早的这个符号主义的，比如证明数学定理，到下围棋、玩游戏，到今天我们去做互联网，去做 coding，去做 computer，去做这些真实世界的数字环境。所以我觉得是有两条线。大家可能往往会看到方法的这条线，但是会忽视了任务的这条线。但我觉得这两条线其实是相辅相成。

Speaker 1: 我其实一直有一个很基础的疑问，就是 open a 有一个五个分级，我们都很熟。从聊天机器人 level one 到推理者 level 2，到代理者 agent level three，然后再到创新者和组织者，这个是 level 4 和 level 5。那这五个分级它内在逻辑是什么？为什么是先有聊天机器人、推理者，然后再有。

Speaker 2: 了 agent 对我觉得这个事情的逻辑是，首先你要有一个语言的先验知识。然后基于语言的现在知识可能你能做出来最早的应用其实就是对话机器人。然后基于语言的这个先验知识，下一步你需要能够推理。就是我们说 step two 就是 reasoner。当你有了很好的语言学知识和推理能力之后，实际上你才能去做各种各样的 agent，或者说能能泛化的 agent。

Speaker 2: 然后我觉得很明显的就是今天 agent 最重要的几个进步的方向，一个就是说能让他有自己的 reward，能让他自己探索。另一个是说 multi agent 能够让他形成组织。我觉得这两个事情我觉得可能是正交的，或者说是可以平行发展的。我觉得谁是在 level 5，我觉得这个我不确定。但是我觉得这两个事情是很显然下一步需要做的对。

Speaker 1: 所以从 level 2 到 level 3，就是你做的这一步训模型到用模型，这其实是一个很重要的一个跨越。

Speaker 2: 或者说从单纯做推理到把推理应用到做 agent 去和环境交互。

Speaker 1: 这里目前有哪些主流的架构，这个形成共识了吗？

Speaker 2: 我觉得我的感觉是，其实百分之大多数时候大家就是用类似于 react 的架构，就是说能够去推理，然后你可以去产生一个 action，这是一个最简单的个事情。但是 again，我觉得最简单的事情可能还是 work 的最好的。然后我觉得可能基于特定的任务，你会有很多 workflow 或者更 so specific 的方法。但是我觉得最通用的方法还是类似于 react 这样的方法。对。

Speaker 1: 保密，你说你自己最看重提升 agent 能力的是哪几个关键能力？之前有人提 context，甚至 long context 的 reasoning，或者说工具调用用或者指令遵循。你刚才一直在提 reasoning，如果提升 agent 能力，你自己最看重哪几个能。

Speaker 2: 我觉得这是一个很好的问题。然后我觉得现在没有一个特别好的能力的 tex omy，或者说这种划分系统对吧？或者说每个人有自己的一个划分系统。就比如可能一个人会划分，比如说这个基于工具的能力，比如说我的 coding 能力，我的上网的能力，我的使用计算机的能力，我觉得是一种划分方法对吧？我觉得另一种划分方法，就比如说我的我的这个处理多模态的能力，我的处理长长 context 的能力，然后我的 reason 能力，我觉得这两种划分都是有道理的对，然后可能对于现在来说，我觉得可能我最看重的是处理 context 的能力，或者说 memory 的能力，然后基于它去做 life on learning 或者 online learning 的 learning。

Speaker 1: 对你刚才一直在提到环境，你感觉 code 代码是一个实现 AGI 最重要的一个环境，可以做多轮的 L 反馈也是闭环的，也是可以验证的那你你你感觉如果在这个环境搭 agent 是不是会更快的？

Speaker 2: 对我觉得毫无疑问，这是最重要的环境之一。我觉得 coding 就有点像人的手一样，对吧？就是说它是某种程度上来说 AI 最最重要的 affordable，就是对于物理世界来说人的 affordable。我不知道这个词用中文怎么翻译，但是对于人来说最重要的 ordance 就是说我要制造出手能够使用的工具，对吧？比如锤子，比如说这个笔，比如说这个筷子，对吧？

Speaker 2: 但是对于这对于对于 AI 或者 digital 的 agent 来说，可能最重要的 affordable 就是 code。对，因为其他的 affiance 其实都是给人定义的。比如说你的这个网页或者你的小说或者别的东西，其实都是给人定义的。只有 code 是一个很自然的是给机器定义的东西。

Speaker 2: 对，然后我我我其实是可能 222 年，当时我就很纳闷一件事情，很显然做 coding 的 A 真的是最重要的事情，那为什么没有人做？然后我们当时做了一个做的 work 叫 into code，就当时所有的人都在做。比如说我有一个任务，我有个 coding task，然后我产生一段 code，然后我去 evaluate。但我们就是说那你为什么不把这个执行的结果返回给这个模型？你去做多轮的这种 agent task，然后把它变成一个环境，而不是一个单纯的任务。然后基于这个我们后来又做了 sweet bench，所以 agent 但有的时候我觉得很有意思的一点就是说很显然一个东西非常重要，但是有的时候就是没有人做。所以说比如说你是一个研究员，你觉得你做的事情很重要，但是没有任何人觉得重要或者在做，那可能并不是一件坏事。可能就是很重要，但是没有人做对。

Speaker 1: 这里有个很强的非共识，有的人觉得 code 可能是这一轮技术革命最大的一个价值体现，但也有人觉得可以泛化到更多的任务里面，在整个电脑、手机数字世界中都可以实现 agent 操作，人能做到 95%、99 的任务。你觉得从 code 到整个数字世界这一步的跨越，或者它的泛化，你是有信心听的吗？

Speaker 2: 我觉得就是从更广义的角度来说，你可以认为比如 API 也是扣的一部分对吧？就是任何基于 code 的这种接口都是 code 的环境的一部分，对吧？然后我觉得有个非常经典的 debate 一个辩论。就是说最终的这个 AGI 它是一个基于 API 的，或者基于 code 的这样一个还是基于 GUI 或者基于对人定义的这些环境的一个东西，还是说它是一个 mix。

Speaker 2: 我觉得这个事情就有点像，当然首先一点就是说很多事情它可能并没有一个 API 对吧？现在它只有一个 front，它只有一个前端，然后你可以去为他造一片，那就有点像是说你想要改造你的车能够适应所有度，还是说你想要改造你的路去适应现在这些车，对吧？然后呃当然我觉得可能最终的结果是 meet in the middle，就是两边都会做，而且可能这个事情没有那么难。就是说现在来看让一个 agent 既能够使用 code，又可以去使用人人的这些 screen shot 或者 front end，可能两者都做也没有那么难。那从这个角度来说，去让 agent 或者让这辆车能够开在所有的路上的难度是低于人力去改造所有的路，让他能能变成 API 接口的难度。那那从这个角度来说，我觉得 coding 肯定是很重要。但是如果去做 GU 或者做其他东西也没有那么难，那可能最终的 agent 就什么都做对。

Speaker 1: 我还想再问一个泛化的问题。因为我读你最新的文章，我印象最深的是你提到这个终于泛化了，就是是真的泛化吗？因为你刚才也提到有很多鲜艳的知识已经到 model 里头了，对吧？那有什么迹象能让你感觉到是真的泛化了，而不是他那个 training data 里面就既有包含这些数据了。

Speaker 2: 对我觉得是有可能就是说如果你的培训内已经包含了所有事情，那 RL 只是激发出来这些所有的 skill。使我想起可能是伊利亚还是谁说的一句话，就是说 maybe the automate finalization，就是说你去 over fit。The reality 就是如果你能把剩下所有事情都干了，那那你在讨论他是 over fit 还是兼容 SU 就不重要了。

Speaker 2: 对，但是我觉得 again，就是它还是 generalized。而且我觉得原因就是它能够 reason，就是说当你可以在一个环境学到一些如何去思考的这个技能，并且这个思考的技能能够迁移到新的环境。我觉得这个是我说他泛化的本质原因。对，从之前的话，之前可能你学到的更多是比如我下围棋，我对这个环境或者对这个游戏有了很强的理解。但是我怎么去用一个像语言一样通用的方式去思考，在这个方面并没有泛化，我觉得这个是可能本质原因。而不是说我学会了上网，我学会了写代码，然后真能够做世界上很多事情。

Speaker 1: 我还想再插一个小问题，有可能我们很快就看到了最强的软件工程师。甚至到 2027 年，我们看到了能操作人类电脑手机上几乎所有的任务和指令的通用的 agent 那你对这一天的这个幻想是一个什么样的？过于乐观吗？还是比较合理的。

Speaker 2: 我觉得这个事情现在还没有 well define，就还没有被很好的定义。就是说从某种程度来说。现在的这些模型，它它写代码的能力已经比世界上几乎所有人要强。或者说它的数学推理或者逻辑推理能力，从某种程度来说已经比世界上大多数人要强了。但是当你要说他能不能很好的使用这些环境的时候，还是要基于你要让他去做什么任务，然后这个任务是不是一个能够被合理定义的任务。

Speaker 2: 我觉得很多时候人或者说人类最难的问题不是说去推理，而是去获得这个 context，或者说获得这个背景。或者说我不知道怎么翻译。就是说很多时候我觉得现在模型的包装，不是说我缺少这个推理能力，或者说我缺少写代码或者使用前端的能力，而是说它缺少一个完整的 context。然后这个事情我觉得我不知道是不是这个 intelligence 的问题，还是一个产品问题，还是一个别的什么问题。但是如果你要让 AI 实现价值，那你需要去解决这个问题。

Speaker 1: 对你在四月的博文的 second half，就这篇博文在四月份引起了很大的反响。你是怎么想到 the second half 这个关键的 idea？当时受了什么启发吗？

Speaker 2: 好，问题是这样的，就是说我首先是被邀请去斯坦福，就是那门课去给一个给个 talk，然后我就去思考，那我能讲什么呢？然后很显然我也不能讲很多很技术性的东西，我就只能讲一些比较哲学的东西。那你讲什么呢？然后就想到这个事情。对，然后我觉得是就是我在 open a 工作半年，包括之前 research 的一个感悟，就是说大家往往看重的是比如训模型或者方法或者别的东西。但是现在我觉得 boss neck 已经转移到了怎么去定义好的任务，怎么去定义好的环境。

Speaker 1: 你觉得现在是那个转折点吗？从上半场到下半场。

Speaker 2: 从某种角度来说，我觉得主线在从上半场变成下半场。我说的主线就是说基于语言的智能体。当然你可以说比如 audio 或者 muli model 或者 robot，还有很多没有解决的方法的问题，对吧？但是我觉得从语言开始，然后定义推理，定义 agent 这条线上面，我觉得我们已经有了一个终于有了一个很尖锐的方法，并且这个方法是可以泛化的那这个事情就带来一个很本质的区别，就是说我们之前是就有点像我有很多怪兽，那我需要去为了不同怪兽去噪各种各样的武器去来打这些怪兽。现在我有一个通用的武器了，就我有一把机关枪。那现在我要思考的问题是我要朝哪里去去开枪，对吧？就是我现在其实不用再去考虑那么多方法的问题了，因为有已经有一个非常通用的方法。那我可能需要更多考虑的问题是，我要用这个方法去解决什么问题。

Speaker 1: 所以就是怎么设定任务，怎么定义问题，这个你在探索过程中有什么思考吗？可以分享。

Speaker 2: 对我觉得不同的人有不同的 flavor，有不同的偏好。然后我是从很早开始就是有这样一个偏好。就是说我想定义一个 reward。这个 reward 是基于结果而不是过程的。而且它是一个基于规则，或者说能够很清晰的算出来，而不是基于人的偏好或者模型的这个偏好，或者一些非常黑盒的东西的。

Speaker 2: 然后就是我们做 web shop 这个工作的时候，其实当时最困难的一点就是说我怎么去定义 reward。实际上我认为做任何的 RL task 最难的部分其实是怎么定义 reward，对吧？因为你永远可以把亚马逊或者把 facebook，就你可以做各种各样的环境。就这个事情工程上非常难，但是这个东西总是可以做的。最难的部分是我怎么去设计任务，让让这个任务既有难度又有真实的价值，又有一个很好的 reward，而且这个 reward 又不是很 noisy，它是一个基于规则或者是白盒的 reward，而不是一个黑盒的 reward。对，然后后我觉得事实后来证明就是说这个是现在的 R1 就是成功的关键对吧？

Speaker 2: 就是说像 max 和 coding 这样的任务，它最重要的一点就是说首先它是基于结果，而不是基于过程的。第二是说我有一个非常清晰的基于规则的 reward，而不是基于奇怪的人或者模型偏好的 reward，吧？就是说答案是 3，那它就是 3。你只要最终这个答案它的它是 3，那它就是对的。它不是 3，它就是错的。

Speaker 2: 如果你去做任何其他的设计，好像都会出现 hiking。如果你基于过程去定义 reword，那你可能会出现 hacking。如果你去优化人的偏好或者说机器的偏好，那你也会出现 hacking。那你可能会产生一个非常优美的代码，但是它可能不解决问题，对吧？然后我作为其他的这些 task，我觉得也是这样的 failure。就比如 sweet bench，包括一些其他的像 colly 或者其他各种各样的任务。对我觉得就是一点是基于结果而不是过程。第二点是白盒的，基于规则的，而不是基于人或者模型偏好的。

Speaker 1: 因为 open I 它对产品有五个分级。如果是基于 agent，就是基于任务的定义来给有可能的产品做一些分级。随着模型能力的溢出，当我们要用模型能力的时候，那 agent 可以怎么做一个分级呢？在你脑海中有这样的。

Speaker 2: 一个框架没有我现在感觉倾向于会有不同的类型的应用，会有不同的挑战。然后这些挑战可能是正交的或者说没有，很难说谁谁比谁更难，或者谁比谁更简单。就是从某种角度来说，人类也有这样的问题对吧？就比如说洛克菲勒和爱因斯坦谁更厉害，这个事情是很难去定义对吧？就成为一个大公司的 CEO 和成为一个数学家，谁哪件事情更难？我觉得这个事情是是他可能是不同的男人或者不同的挑战。

Speaker 2: 但是对于 A 正来说，还有另外一点，就是说可能对于人来说一个很简单或者很难的事情。对于 agent 它可能并没有这样的简单和难的区分。就比如说可能对于人做对于人来说，作为一个客服比作为一个软件工程师要简单很多，对吧？他工资也少很多，然后需要的文凭或者需要的各种各样的资历也少很多。那现在反而做软件工程是比做克服我觉得更简单的事情。因为做软件工程，你有一个更好的环境，有一个更清晰的 reward。然后你有更多更多的数据或者各种各样的原因。你想要去做一个非常 robust 或者 reliable 的客服，实际上是有这个 reliability 的 chAllenge。

Speaker 2: 所以我觉得我们可以把人类的各种各样的工作分成了很多各种各样的 category。但是人本身就有很多不同 aspect 的 chAllenge。然后对于机器来说或者对 AI 来说，人的这些 chAllenge 的相对难易可能也不完全反映到 AI 上了。

Speaker 1: 那什么样的任务整体来说更适合 A 阵做，什么样的任务比如说适合人和 A 证一起做，然后什么样的任务适合人做。

Speaker 2: 就是我觉得从非常 high level 说，我觉得有不同的划分任务的方法。对我觉得从一个划分方法来说，有一些任务更注重 reliability，或者有些任务更注重 creativity。就是说做客服你重要的是，比如说 100 次里面你需要 99 次或者以上不要出错，对吧？如果你比如你只有 85 次让用户开心了，你有 15 次没有让用户开心，那你可能就被炒鱿鱼了。那就是说我觉得一个任务就是说你做简单的事情，但是把它做得非常的 reliable。另一个任务可能是比如说我要去证明黎曼猜想，或者我要去写一个很难的代码，或者我要去创作文学剧本，对吧？就是说我可以试 100 次，我只要有一次做的特别好，那我就成功。然后这两类任务我觉得需要的挑战是不一样。

Speaker 2: 我觉得还有那还有另一个划分就是说你是去做我觉得任务的深度和广度，就是说你可以去做一个，比如说我 curse 其实是一个非常短的 loop。比如我把这个文件改一下，可能我三秒钟做好了，有些事情我可能需要 30 分钟或者 3 个小时或者三天。从这个维度来说，就是说我需要的是长期记忆或者 lotter memory 的这个能力。然后从任务的广度来说，比如说我要去解决这一个 bug，faces 我要从头搭建，比如 windows 这样的一个 rapper，那那我会有这个广度的区别，对吧？就是一个人能做的事情和一个公司能做的事情，和一个 team 能做的事情。那那从这个角度来说，我觉得我们需要 multiple ent research。

Speaker 1: 从 reliability 到 creativity，哪个任务是 A 制的？目前更好定义的它的顺序和步骤应该是什么样的？

Speaker 2: 我觉得其实我们是可以平行的做很多不同的事情的。而且其实有一个非常简单的就是设计没设计的方法。就比如说做 coding，我们有一个非常传统上有一个 MC 叫做 pass at k 意思是说你做了比如说你同样一个代码写的 case，你起码成功一次的概率是多少。那你可以想象就是说当你这个 K 越来越大的时候，你的成功概率会越来越大。然后你会发现很多时候这个 coding reset 它会 report pass at a hundred。就是说我同样一个任务我跑 100 次，我起码成功一次的概率是多少？

Speaker 2: 对，但是我们我们去年发了一个 research 叫做 top inch。他的想法就是说实际上对于另一类任务，比如说客服你需要是和他正好镜面相反的 matter，叫做我们把它定义叫做 pass。Header 就是 head，就是一个幂次的那样的一个符号。就是说你做 css 永远永远成功的概率是多少，或者说起码失败一次的概率是多少。

Speaker 2: 我觉得从某种程度来说，我有些任务我们需要去 optimize pass c 有些任务我们需要去 optimist ass head，但是往往我们现在更重视的是 success rate which is pass at one，或者是我们重视 pass at a hundred。对于 coding。我们对于简单任务的 robustness 并不是特别重视。而这个事情的原因，我觉得是因为大家做 AI 还是没有还是在做一些 benchmark 对吧？

Speaker 2: 就大家还是在做我做一些任务，而没有说我要去做一些实际的应用。但如果你要接受这个 mac 转变之后，我觉得很自然。就有些应用它就是需要 business，那我就是需要去 optimize。现在我觉得还没有意识到这件事情，但我觉得如果大家意识到这个事情，这个事情是会有很大进步的。

Speaker 1: 其实创业公司很担心模型能力的溢出，会把创业公司做的 A 阵吞掉。长期看像 Chris 这样的公司，你觉得它的壁垒是什么？就你觉得哪些 agent 是模型公司必然一定会做的，哪些事情是有创业公司机会的？就他这个边界你觉得可能在哪里？

Speaker 2: 我觉得创业公司应该担心的事情是模型没有溢出能力，对吧？那这样的话你就真的什么都做不了了。我觉得有艺术能力是个非常好的事情，这几乎意味着你有机会，对吧？

Speaker 2: 然后我觉得创业公司最大的机会就是说，我能够设计不同的 interface，或者说人和数字世界交互的方式。就是说 ChatGPT 或者这些所有的做模型的公司，其实都在做类似拆 GB 的产品。然后 chat BT 的本质就是说你是在像和人交互一样去进行和这个数字世界的交互，对吧？就是说你的 chatbot 有一个对面有一个像人一样的东西，然后你和他聊天，或者你给他布置任务，或者你让他去帮你做 deep research，或者让让你帮他做所有写代码。但它的交互方式是一个像人一样的交互方式，或者是像助手一样交互方式。如果你能够用模型通用能力，但是创造不同的交互方式，那你就能创造巨大的机会。

Speaker 2: 我觉得本质上来说，curse 就是说我创造了一种新的交互方式，对吧？就是说它不是一个像人一样交互的方式，而是一个像 copilot 或者说是一个新的交互方式。我我我写这个代码的时候，他能给你提示一些东西，或者我能帮你这个 ID 的一些东西。但是没有人和人是这样交互的对吧？这也是它的价值所在。我觉得最终可能模型的能力是会比是会产生 beyond ChatGPT 这种交互方式的 super APP。

Speaker 2: 这种情况下，创业公司最大的机会就是说我能探索新的交互方式，并且我能够有模型溢出的能力，这两者缺一不可。如果你做的是这个旧的 interface，然后你用利用这些新的模型，那你很很容易被 ChatGPT 取代，对吧？如果你的交互方式很像 ChatGPT，那你有什么理由不被 chat BT 去取代？如果你做新的交互方式，但模型没有继续变好，没有新的溢出能力，那你也很难做。所以对于创业公司来说，最好的机会就是说你做新的交互方式。但是模型不停的有新的艺术能力，让你能够赋能这些新的交互方式。

Speaker 1: 插 GPT 也可以有跟进这个新的交互方式。

Speaker 2: 但是我觉得拥有一个 super APP，其实对于公司是双刃剑，对吧？因为当你已经有了一个交互方式的时候，你会必然的形成路径依赖。就像 2020 年 google 它有无限多的资源和钱，有 transformers，有有最好的 research。但他可能最自然的想法是我怎么用这东西提升我的搜索引擎。

Speaker 2: 当你有像 ChatGPT 这样一个 super APP 的时候，那很自然你的 research 就会 around 这个 super APP 会生存。而 run 这个交互方式，你会去探索新的产品。但是即使是大厂或者即使是谷歌，即使 open，你大部分资源还是会围绕你的 super APP 的这样的交互方式。这我觉得这是创业公司的机会。对。

Speaker 1: 有趣。你刚才提到交互方式，今天还是人跟 code 交互，人跟 tax 交互，那人跟 agent 未来是怎么交互的呢？你感觉超级助理那种 her 那种属于一个正确的交互方式？如果这种交互方式 work，你觉得有没有机会闭上 CGP 今天的形态呢？

Speaker 2: Her 其实是不是类似于一个还是一个 assistant 的形态，但是只不过它有语音而不是文字，对吧？我觉得这是一个很显然很有价值的心态，对吧？因为人和人交互已经几千年、几万年、几百万年，这是一个对人来说最自然的形态，这肯定是最显然的 super up。但是然后这个生态位我觉得 ChatGPT 是站住的，或者说很显然这些模型公司一开始做的事情就是这个。

Speaker 2: 那我觉得不显然的事情是我能不能基于不像人的交互方式？我觉得科学是一个很好的例子，然后从某种程度来说，google 是个很好的例子？就是他当时这是一个很新的方法，就没有人见过，很奇怪。对。然后雅虎从某种上来说是一个更像黄页的对吧？是一个更让人熟悉的交互方式。但是谷歌是一个更让人不熟悉的交互方式。我觉得 assistant 或者 her 或者就和人一样，交互方式是一个很显然的最重要的交互方式之一。但是我觉得肯定还是会会有足够多的机会有新的交互方式产生。

Speaker 1: 你脑海里有没有一些新的交互方式？就是非 ChatGPT 现在在探索的心态，也非传统的互联网的交互方式，在你脑海里有吗？

Speaker 2: 我觉得 canvas 是一个好的尝试。就是说你可以基于现在的一个任务去去在线生成一个最符合这个情境和你的个性和这个任务的一个前端。然后你可以让这个东西对不同的事情做的很不一样。我觉得这是一个很显然值得探索的方向。但这个事情显然也很难。

Speaker 1: 对你感觉应用公司的数据飞轮对他们非常重要吗？或者说在什么环境下才能形成？我感觉 check boat 就是偏好数据，好像没什么数据飞轮。Code 可能有思考过程的数据，思考过程的数据是代表一类能力的数据，这个可能是有用的。像 canvas 也好，artifex 可能是有思考过程的数据的那这里能有机会形成很强的数据分析效应。

Speaker 2: 我觉得大多数公司还没有形成数据费用，对吧？大多数公司还是依赖于模型在变好，然后使用模型变好的这个溢出的能力。然后如果你要有数据飞轮，首先你要能够自己去训模型，并且你能够通过交互有一个很好的 reward。我觉得就是你要有一个好的 reward 的，使得你能够把好的数据和不好的数据分开，我觉得现在可能比较成功的案例就是 made journey，就是说我有个非常清晰的 reward，就是说人更喜欢哪张图，然后这个 reward 和我的应用是闪的。就说我这个 reward 做的更好，那我这个公司就是更成功，然后这个模型就是更好一些，东西都是对齐的。

Speaker 2: 然后有了这样的一个情况下，我又能自己去模型，我可以去做数据飞轮。然后你做的这个事情又必须比较不主线。因为如果是很主线的话，我也可以通过 p training 或者 RL 或者一些别的方式去把这个能力给提上去，对吧？然后我可以通过泛化，我可以通过别的方式。所以现在我觉得对大多数大数公司好像并没有形成飞蛾。

Speaker 1: 对如果你是科学的 CEO，你会去做 pretrail ing. 

Speaker 2: 的事情是个好问题。对我觉得我肯定会训练模型或者去尝试训练模型，但是做不做 pershing 我觉得得得看情况。对我觉得 cody 是一个非常主线的任务，就是所有的现在大厂他都会把自己的模型的 coding 做好，对吧？所以所有的 prefiling，还有 post reading，还有二各种各样的事情，他都会考虑到这一点。在这个情况下来说，你要不要做它可能取决于首先就是这些闭源的这些模型做的有多好。其次是开源模型做的有多好。然后这中间有有多少 gap，然后你能够填补多少这样的 gap，对吧？那那可能那当然比如如果你有很多钱，你那你有很多资源，那你想把这个事情做了，那我觉得也是合理的对。

Speaker 1: 围绕 A 阵，你脑海里的一个数的结构是什么样子的？如果是基于 function model，然后基于 reasoner，然后往上涨，这个 agent 的整个的生态树，你你在你脑海里是一个什么样的结构。

Speaker 2: 我觉得就是有有两个有两个方向。一个方向是 fundamental 的 research 会怎么演变，或者说这个方法会怎么演变。我觉得另一个是应用，或者说它的交互方式会有什么样的演变。然后从某种程度上来说，他们之间肯定是有关联，但是我觉得会需要不同的人探索不同的方面，然后比如科 sir 他就是我我并没有在产品或者 fundamental research 上做创新，但是我做交互方式的创新。

Speaker 2: 然后我觉得在放在 winter research 上，我自己觉得比较重要的就是一个是一个是 memory，一个是 interesting reward，还有一个事情是 multiple。就是说我怎么我怎么能够让一个 agent，这个事情我觉得也和 OpenAI，就是接下来说的这个 innovation 和 organization 很像，其实就是你作为一个 innovator，首先你需要一个 long term memory，比如我怀尔斯，我研究费曼费尔曼定理研究，比如说 20 年，那我需要一个拉通百米，我有我需要一个长期记忆。但是基于这长期记忆还不够，你需要有一个内在的 reward？因为直到你证明的那一刻，你是没有任何外在？你也没有获奖，你也没有做任何事情，没有人给你任何 feedback，你需要自己给自己一个 feedback，这个事情是所有 innovator 最重要的事情。无论你是艺术家，还是科学家，还是文学家，还是任何创作者，对吧？另一方面我觉得作为组织。你需要解决的就是说 agent 和 agent 之间怎么协作，怎么让 multi agent skill。

Speaker 2: 然后我觉得从某种程度来说，现在的 agent 可能就像一个普通大学生做做一个数字化的实习生，对吧？就是说可能这是第三节，或者我们说 AGI 可能就是一个普通，比如一本大学生能够在电脑上能做的事情的一个能力。但是人类社会的边界就是说这当然是 80%或者 90%的人。人类社会边界也会说，我们最崇拜什么样的人呢？一方面就是这些创新的人，爱因斯坦或者高跟，或者梵高或者贝多芬，能能创造新的东西的人。另一部分就是我能创造新的组织或者伟大的组织的人，就像伊朗 musk 或者 Steve jobs，那那我觉得很自然，就是这两个事情很重要。对你你说的。

Speaker 1: 实现这个愿景，我感觉中间还有几个关键的东西要突破的。你比如说长期记忆，你感觉长期记忆是一个短期可以预期突破的问题吗？

Speaker 2: 也许，当然也取决于多短期多，但是我觉得必然会突破的就是一个事情，大家总会有价值，总会有突破的对，如果你对技术乐观的话。

Speaker 1: 这个你要展开讲一讲。这个是从 context log context 下手，是在模型的架构本身发生一些变化。

Speaker 2: 我不知道我能 share 多少，但是我的 belief 是说，就是我在博客里面提到的就是 utility 问题，对吧？就是说为什么我们现在这个模型的能力推理这么强，考试这么强，玩游戏这么强，但它还没有创造足够的经济价值。我觉得其实可能根本的原因就是它没有这些 context。

Speaker 2: 然后在人类社会里面比较 tRicky 的一点就是说，当然我们写下来很多东西，我们用文字，用 goodt、用 notion，我们记录下很多东西。但是有很多 context 永远只是在人大脑里面。这个基于分布式的这样一个维护的对吧？就比如说你老板跟你的一些行为习惯，或者一些很难用语言总结下来的东西。这些 context 它存在人脑海里，人永远没有办法把这些东西全部写下来，这就导致人是不可或缺的。因为只有人有这种能力，就是说进入这样一个环境，然后去获得这样的一个 context，对吧？

Speaker 2: 就是说如果这个问题解决了，那我觉得可能有推荐问题就可以很大程度解决，因为这个世界上大多数人并不是 Steve jobs，或者也并不是爱因斯坦。他可能只是一个普通人，他数学推理能力或者 whatever 也没有欧三强，但是他能够去 manage context。他比如说他去了这个公司七天之后，他除了这些文字上看到的东西之外，他脑子里面有一些积累下来的 context。然后这个 context 是你比 O3 有优势，对吧？因为 O3 没有这些 context，你有这些 context，虽然你没有 O3 聪明，但你有这些 context，所以你做的比我才好。

Speaker 1: 对你刚才提到一个很关键的就是模型或者 agent 要有一个内生的奖励系统。那今天是不是好像还没有？如果要赋予他一个内生的奖励系统，是不是我持续自主学习的过程当中，我就可以改动我的一些模型的权重，那就变得更加的聪明。你感觉离这一步还有多远？

Speaker 2: 我不知道，我觉得会有这一天，但是很难预测什么时候。对，当然就是说当然他自我提升的方法也许是改变自己的权重，也许是有一个基于语言的长期记忆，也许是一个基于 ebel ding 或者其他东西的长期记忆。但是他会自我提升。但是具体是什么方式，什么时候，我觉得这还有不确定性。

Speaker 1: 内生奖励你要讲一讲吗？

Speaker 2: 就像我刚刚说的，就是说很多创新者，他为什么能够在没有外在激励的情况下去做很多事情。他是有一个自己内在的价值观或者激励？然后这个事情其实我觉得 AI 或者 neo SINE 已经研究了很多年。

Speaker 2: 从某种程度上来说，婴儿是有这样的一个基于好奇心或者这个自我的 reward，对吧？就是你会发现很多婴儿他会玩这些玩具，他会用嘴咬咬这样一个东西，或者干别的。那你说他获得什么 reward 了吗？他也没有升职加薪，他也没有获得钱，他没有这些外在激励，他就是好奇对吧？他他就是说如果我做这个事情，那我会有什么样的感觉？这个感觉如果是新的，那我就可以学习吧？

Speaker 1: 就是他获得安全感。

Speaker 2: 对，就是说好奇心或者掌控感或者安全感，就是有一些这样的内在的 motivation 使得他做这些事情吧？否则的话你很难从一个理性角度解释他为什么会做这些事情。但是很有意思的是我觉得当人长大之后，他有了一个就当你是婴儿的时候，你其实是一个基于视觉，基于物理世界的对世界的一个理解对吧？就是说你学习的是怎么把你的这些触觉、听觉、视觉和你的运用骨骼的这些各种能力给结合起来，但当你长大之后，你有了一个基于语言，或者基于推理，或者基于文字对世界的一个理解，就这个世界是怎么运作的，我去我怎么才能开一个公司，我怎么才能升职，我怎么才能做各种各样的事情。

Speaker 2: 你在玩的不是一个物理游戏了，而是一个文字游戏。在这个文字游戏里面，你当然也有这样的内在基地，但好像又很不一样。我觉得这是现在的一个挑战。就是说传统的 AI 它比如说你去玩迷宫，或者你去玩一些机器人的仿真，它可以定义出来一些比如基于世界模型，或者基于各种各样人婴儿时候的这些 motivation 的这样的内在激励。但当你在玩一个文字游戏的时候，你怎么去做一个内在激励，这似乎又变得很不一样了。

Speaker 1: 在你研究 A 卷的过程中，你有对人不管是思考还是任何有更深的认知吗？那你怎么看人和 A 症他们的同与不同？

Speaker 2: 最大的感触就是我意识到人之所以能见到 X 是因为能推理。我觉得这个可能是最重要的 take over。然后我觉得这个事情很有意思。因为我我 18 年的时候在 MIT，我在 josh talib 的实验室，他是一个认知科学的大佬。然后我学了很多认知科学，然后认知科学或者计算认知科学，它的一个核心的故事就是说我应该就我们现在这些 AI 虽然有很多进展，但是还有很多问题对吧？然后我们要去看看人是怎么，人有哪些优势，然后人是怎么去做这些事情的，为什么人能把这个事情做得更好？比如人能够从几个样本中泛化，但是机器不能。那为什么我们要从人身上寻找这些方法，然后去把它应用到 AI 上？

Speaker 2: 后来我的认知是你会你会发现现在 work 的这些 AI 系统，它还是会和人很不一样，对吧？就是 skinning law 或者 R 或者很多东西，它和人学习方法就是很不一样。我觉得可能一个更好的从人身上借鉴的方法是你去思考人能做什么，而机器现在不能做，这是一个客观的事情。但是你找到这个问题之后，你可以基于第一性原理去思考怎么去解决这个问题。你不一定要去依赖于人怎么解决这个问题。而解决这个问题。就比如说人我觉得他现在能做的事情，比如说我能进一家公司，我能够工作七天，或者当个实习生当三个月，然后我能积累这个公司的 context。然后我虽然可能不是很聪明，我是一个二本的或者一本的毕业的学生，但我可以做很多现在 AI 做不了的事情。这是一个客观存在的事实。

Speaker 2: 那怎么解决这个问题？可能认知科学或者神经科学会告诉你，人脑有这样的海马体或者 episode memory，或者有这样的架构那样的东西。但我觉得你可能不需要去完全照抄这样的事情，你可以去从第一性原理设计，not memory 要怎么设计。所以我觉得从人身上可以借鉴的是有哪些是人是能做或者机器做不了，这是一个很 robust 很很客观的事情。但至于人是怎么能做这些事情，以及我们要多少程度上借鉴这样的一个方法，这是一个我觉得更主观或者更高级的问题。因为一方面神经科学或者认知科学，它也没有说百分之百解决了这些问题，他只是说我提供了这样的猜想。另一方面是即使他是一个被 confirm 的事情，比如说人人的视觉其实是个相对被研究的更深刻或者更透彻的事情，对吧？人有六层的这样的 core tex 然后它每一层有各种各样的结构。那那我觉得你可以学到的 take away 是说我需要去做这样一个 new network，那我但我并不需要去照抄，就是说它有各种各样的细节。

Speaker 1: 如果在设计 A 证的时候，需要让它越来越像人吗？

Speaker 2: Again 我觉得是一个 util sy problem，我觉得很多问题不像人更有价值。比如下围棋或者 i don't know 就是开车可能可能大多数人开车方向并不好，对吧？那可能这基于这个规则有更好的开车方式，但有些东西像是更好，那你就应该思考怎么去 bridge the gap，怎么去填补这个空缺。下围棋或者打游戏，no 我基于而言，我可以学到和人不一样，并且给人比人更好的方式。那那我就不应该像人，但是在一个公司打工，然后和老板搞好关系，然后去完成各种各样的任务。这个事情人就是比 AI 现在做的更好。那那那我们就应该试图更像人。对你怎么。

Speaker 1: 思考人和 agent 未来的关系，要给 A 就是发身份证吗？

Speaker 2: 我我我觉得这是一个交互方式的问题，对吧？就是说很有可能未来有很多 agent 但他长得并不像人，或者你和他交互的方式并不像人，他可能是个平台或者是一个。或者是页面，或者是一个游戏，或者是一个别的东西。那你可能就不会把它拟人化，对吧？但当然我觉得肯定会有很多拟人化的这样的 agent。

Speaker 1: 如果 agent 他有了长期记忆，他是不是就是你的朋友了？他是你的朋友了，那人跟 agent 就平等了。是不是我们就要给他发身份证？

Speaker 2: 发身份证的目的是什么？

Speaker 1: 就是他作为一个独立个体跟我们共存了。

Speaker 2: 我觉得会有可能，很显然一个很有价值的，我觉得这件事情最终还是会从有的出发点？就是说一个事情如果有价值，那他可能就会产生。比如说那人可能很多人很孤独，他需要一个朋友，那这个技术它能够创造这样一个体验，拟人化就是一个很合理的存在的未来，对吧？但当然他去做一个平台，他去做一个推荐，他去做一个游戏。他可能这个技术会有很多不同的交互方式，让你感觉他不像一个人，或者你根本感觉不到有什么区别。在这个效果上你不会把它拟人化。所以我觉得还是会基于这个事情。

Speaker 1: 的经济价值。对你提到经济价值，就是你觉得 AI agent 跟 crypt to 会有未来结合的地方。你比如说 Crystal 这一套智能合约跟 agent 的结合。未来一个 agent 帮我完成了某个任务，它有一个公允的价值的计量，然后任务完成后，那就按照智能合约的约定就分配这个经济利益了。其实这样是有机会探索出来一个叫 value base 的商业模式的。只是说今天可能咱们还不才能衡量这个任务的客观公允价值到底多少。

Speaker 2: 对我我对 Crystal 了解不多，但是我觉得可能一个核心的问题是，就这个技术的演变，它会变得更中心化还是去中心化。然后我觉得两边都有它的 argument，对吧？就中心化就是说很显然现在这种新的 super company，比如说 open 或者 topic，它有可能比如说会变成 one trillion、ten trillion、trillion， 他可能会占据绝大多数资源，他就会占据绝大多数 compute，它能创造这个 super APP 或者 super platform，它会有巨大的中心化的优势。

Speaker 2: 去中心化的 argument 就是说我每个人的个体是赋能的对吧？就是现在之所以人和人有这么大差距，各种各样的信息差、认知差，各种各样的智能差。如果智能变得非常便宜，就像电一样，从某种程度上来说，它也能给大多数人一个赋能，对吧？其实我觉得这个事情还是挺有意思的。

Speaker 2: 然后我最近的思考是这样的，就是说我的感觉是人类社会是一个网络，对吧？然后它其实是有两个重要的性质。一个性质是说它的中心化程度，或者说它资源分配的集中性。然后我们发现就是说可能原始社会它是一个非常平均的，它逐渐随着技术发展，它越来越中心化。或者说你可以说 28 定律，或者说马太效应，或者 whatever，对吧？但是有另一个你另一个维度就是说你创业成功，或者从一个网络边缘到中心的这个可能性，或者速度能有多快。

Speaker 2: 我觉得从某种程度上来说，为过去几百年发生的事情是这样的，就是说首先这个网络变得更中心化了，对吧？就是说贫富差距变得更大了，或者 28 定律买票效应。但另一方面，其实穷人的或者平民的机会可能是更多了，对吧？如果你在古代，比如门阀制度、九品中正制或者欧洲的这个贵族制度，那你可能农民就永远是农民，或者印度的种姓制度对吧？你有阶级固化。

Speaker 2: 似乎技术发展的趋势是两者都会加剧，对吧？就是说一方面中心化会加剧，因为效率是一个根本性的原因。但另一方面可能创造新的东西的机会，起码目前为止还是越来越多的。但是不好说就是说社会是未来的趋势，对吧？有可能就还是会延续这样的趋势，但是也不一定。

Speaker 1: 你在你的博文里面提到 open I 的几次尝试，我觉得很有意思。最初的计划是构建 jim 一个用于各种游戏的标准，强化学习的环境，然后是 work of base 和 universe 的项目。但这也没有奏效，直到 GPT two 和 GT3 出现了，才发现缺失的是经验知识。这个过程就 OpenAI 的几次尝试，能不能给我们详细讲讲？这是也是一个探索的过程。

Speaker 2: 这个是我是我自己的总结和和揣测。对，不代表我觉得 open I 是一个非常是一个比较 bottle map 的公司。它是一个他最初的可能七八年就像是一个 research lab，对吧？

Speaker 2: 有各种各样的想法，然后有各种各样的尝试，可能每个人想法都是不一样的。但是客观上来说，一开始的是 focus 强化学习的。因为当时最火的事情就是这个，对吧？Deep one 的他就可能 15 年刚成立的时候，就当时 AI 最火的公司是 deep 的。Deep one 的最成功的东西就是强化学习。然后在 GPT 之前，可能阿法狗就是最成功的 AI 项目对吧？

Speaker 2: 那很自然的就是你要去做强化学习，然后你只有有个 different beat，你才能够超越之前的霸主，对吧？就是说我觉得如果 open a 一直做强化学习，那可能也很难超过 deep man。即使你做得很好，或者有些有些他有些任务你做的比 deep man 更好，但是将枪学期大家只会想起来 deep。所以从某种程度来说，你想要超越之前的这个霸主，你就要有个 different bet。然后 turns out GPT 是这样的一个 different bat 当然这个事情其实还是一个很非共识的事情。就是我可以讲个故事，就是我导师他是 GBT1 的第二作者，对，然后他在 open a 待了一年，然后去普宁当教授了。然后他当时对这个事情就有点怀疑，所以他说当时结果也特别好，对吧？

Speaker 2: 就是那些榜单上也不是分数最高的，然后你花了很多卡或者做这个东西的，当时其实也有 skinning law，17 年刚出来，伊利亚就跟我的导师说就卡 sic 你看这个预言已经被我们解决了，现在我们只需要 skill up，这个东西就结束了。但即使你是在 OpenAI，即使你在这个环境，即使你是 GPG 的作者，你可能还是没有形成共识，对吧？所以这个事情我觉得就是说你做了一个非常当时反共识的事情，当然现在这个事情已经是共识了。那那我觉得就是你需要去寻找下一个反共识的事情。也许对刚才。

Speaker 1: 就是你导师说的那个话之后，有人有 feedback 吗？

Speaker 2: 我说实话可能当时 open a 可能绝大多数人也不认为 scout PT 是最好的方向，或者说是最 promising 的方向，我觉得这个是有可能的，每个人都在做不同的事情，对吧？有些人在做 robotic，有些人在做这个或者那个。我觉得可能伊利亚最大的贡献就是虽然他不是做 GPT one 或者做这些具体技术的人，但他是号召我们要 all in 这个方向的人我觉得从某种程度来说，达 real 也是他的最大的贡献。也不是说我提出某个具体的技术，而是说我做一个创业公司，我敢赌，就是说我敢赌就这一个事情，然后我把钱都砸进去了。

Speaker 1: 所以有人愿意去做 GP3 是特别关键的。像 dara 也好，tom Brown 也好，他们敢于把 GP3 做出来，其实让人看到了更大的希望。泛化了。

Speaker 2: 当然这个事情的好处就是说你并不需要所有人达成共识，对吧？你只要有足够多人达成共识，你就可以做这个事情。

Speaker 1: 你觉得接下来几年中还会有更多的 GPT3 的 moment. 

Speaker 2: 我觉得就是会有新的 skin dimension 出现对吧？就是说如果你有 long memory，那你的 test time computer 会有用新的方式 skill。如果你有了 multiple，那你的 test time computer 又有另一个新的维度去 skill，我觉得会有新的 skill 的 dimension 出现。但是当你有很多 skill WH 之后，怎么去选择，怎么去基于某一个应用去选择这不同 skill 的比重，我觉得会是一个很有意思的问题。对刚才。

Speaker 1: 那个问题就是内部之前没有形成共识，后来强化学习在什么时候变得特别重要？对于欧朋海内部来说。

Speaker 2: 我觉得强化学习一直都很重要。就是说即使我在做 GPT 的时候，就江叔们他们还是在就还是会有人在做 21。他并不是一个说我做 GPT 之后，我就把 R1 全部扔掉的事情。而是可能说我公司 80%或者 70%的资源做这个事情，然后我其他一些别的东西还在做，然后我觉得这个事情其实也很重要的对吧？

Speaker 2: 因为后来证明拆 GB 的成功，R 一也是很重要的。如果没有 RHF，没有这些 limit 的技术，那它也没有办法形成一个产品。所以历史并不是说我走了这条路，然后我把这条路彻底抛弃，走了另一条路，然后我再返回来再走另一条路。而是跟 soft 对吧？就是说我在做很多事情，然后这个事情很 promising，所以我把它下了更大的赌注，但有些其他东西我还在接着做。

Speaker 1: 也有一句非常 lab 的总结，就是语言通过智能体中的推理实现了泛化。它的泛化是一个已经被证实的事情，还是一种推断。

Speaker 2: 就是说为什么为什么语言非常独特或者非常好？就是因为它是人和人或者说人在这个世界上完成各种各样事情的一个工具。就它就就你某种程度上来说，语言也是一个人类发明的工具，对吧？就像火或者像笔一样。但它之所以特殊，就是因为它是一个帮助你解决任何事情的一个有通用或者泛化性的工具。

Speaker 2: 当你学会了这门工具之后。你就可以去做很多新的任务。比如你学会了攀岩，对吧？但是他可能不能帮你去做很多新的任务。但你学会了语言之后，他几乎总是能帮你去做新的任务。因为你可以和人交流，可以学习，可以去以去思考，可以去推理。

Speaker 2: 从某种程度上来说，20 年以前大家很多时候没有把这个事情想清楚。就大家认为我们有语音、有文字、有图像、有视频，有这些东西，它其实都是一些数据，对吧？当然那那可能也没什么区别，对吧？那那我觉得可能最大的区别就是说，语言是一个人为了实现泛化而发明出来的一个工具。然后这个世界比其他东西更本质。

Speaker 1: 这说的是语言能力，还具有泛化能力。强化学习终于具备了泛化能力，它是一种推断还是一种结论？

Speaker 2: 我觉得是可以说是我个人观点。但是我觉得其实有很多人在在讨论这个事情，就是泛化与否当然是一个 spectrum，它是一个相对的东西，对吧？就是嗯不是一个零和一的绝对的事情。但是我觉得我之所以这么说，是因为在此之前，如果你去在一个环境上训练，你只能做这一个环境。但是现在你在一个环境上训练，你可以去做更多环境，我觉得这是最本质的区别。

Speaker 2: 你可以 deep stick，就是说你可以在 deep stick，大家说它的这个比较有意思的结果就是说你在 max 和 code 上做的 RL 但你可能在创意写作上也变得更强。我觉得这个是一个本质的区别。阿尔法狗它只能下围棋，它不能下象棋。但是你现在比如说你学的数学，你可以去做创意写作，我觉得这是一个本质的区别。

Speaker 1: 你觉得你训练打这一类游戏强了，它可以泛化到打其他游戏都很强吗？你比如说打 dota 很强了，他是不是打所有的游戏都很强。

Speaker 2: 我觉得不好说对吧？就是说机器人推理它在不同环境下它的泛化可能也不一样。比如说可能这些基于逻辑的推理，它可能从数学到 coding 的钱也会更容易。然后基于比如人情世故的推理，他可能在另一个另一些 task 上迁移的更好。我但我觉得可能重要的事情是说，你现在终于有一个可能的 single model 可以去做所有 task。之前我们认为这个事情是不太可能的，但是我觉得现在是有可能的。就是说你去你可以同时在很多首先你可以在很多不同的任务上去做 RL，并且他能够去 transfer 到更多任务。当然就是说你如果只考虑 task 和 task 之间，那他肯定迁移的程度是和他的 tsk 的性质有关系。

Speaker 1: 代码和数学之所以能容易泛化，你有想过背后的原因吗？是因为他们有过程思考过程吗？

Speaker 2: 我觉得只是因为他是最早开始做的事情了，而他最早开始做的是因为他比较简单，就是说它有一个很好的 reward，然后它它不需要一个环境，它就是 reasoning。那现在来看可能很多其他事情也是可以发发的，只是我们一开始做的是这个事情，所以大家现在对这事情讨论比较多。

Speaker 1: 有一个 agent 的创业者想问你，agent 如何 scare up？因为现在的瓶颈主要是算力，agent token 用料非常的可怕，单个用户的消耗可能是 chatbot 的 500 到 1000 倍，再叠加几百万用户。所以你觉得 agi 怎么 give up？

Speaker 2: 我觉得可能最重要的点是要找到一个好的应用，对吧？就是说我觉得 cos 本身不是问题，问题是你的 cost 不 justify 你的 performance，或者你的 value。如果这个很有 value 的事情，我花了五百刀，但是我可以给我赚一千刀，那 that's not a problem。它不是一个问题。

Speaker 2: 我觉得可能现在来说最重要的事情是找到有价值的应用。然后 cost 我觉得总会降低的对吧？就是这个模型的能力会提升，价格 cos 会降低。但是找到好的应用，有价值的应用是最本质。

Speaker 2: 当然不同的应用就是说你去做的方式可能也不一样，对吧？就是可能你去做一简单的任务，那我可以去训练这个模型，我去做一个小模型，我可以让他我可以让它更快、更便宜、更针对这个 task。我如果做一个像更难的，比如我去做投资或者去做这个 deep research，那我可能就需要个大的 model，那我可能有不同的方法去平衡这个 cost 和这个 value。但是我觉得最重要的事情是先找到一个东西有 value。那那这个事情找到之后，costs 总会有办法下掉。

Speaker 1: 你感觉 agent 的创业者，他的背景里头一定要有 research 出身的人吗？Researcher 这个有什么优势或劣势吗？

Speaker 2: 我觉得不好说，我觉得还是挺看人的。就是我觉得很难把人分成 research 和 research 两类，这两类有很强的区别，我觉得人和人之间还是区别很大的。我觉得可能最重要的一点还是找到这个 value，大家把它称为 prod market fit，或者称为产品的 sense，或者什么都好。就是我觉得找到这个 value 是最重要的，技术只是一个手段，目前来说，就是最重要的事情解决问题，找到好的问题，然后可能反而你有很强的 research 背景，或者自然语言处理或者别的这些背景，反而是个坏事。因为你会太执念于这个技术，你会拿着这个锤子去找钉子，对吧？现在来看最成功的这些应用创业者似乎都不是，比如说做 NLP 或者 AI 的东西。我感觉比如科他是四个本科生，然后当然 properer ity 好像创业者是一个是一个是个是个 researcher，对吧？就是我觉得这还是挺看人的，就是和你们做过 research 可能关系没有那么强相关。

Speaker 1: 你怎么看 minus、j mark 这些产品和他们的 founding？

Speaker 2: 我试过 minus，但我还没有试过 just mark。对我觉得我觉得 max 还是挺有意思的。对我觉得给我一些还是给我一些启发的，我觉得他们产品 sense 很好，他们有打磨产品的基因，我觉得对这个产品。

Speaker 1: 应该是 open I 的主线上的产品。

Speaker 2: UC 我就基于 max 我再讲一点，我觉得很有意思的一点是说，传统上大家认为发生的事情是，比如我大厂先做出来一个东西，然后创业公司就可以开始抄，对吧？比如说我做出来拆 GPT，那我可以去抄抄 GPT，或者去做一个类似的事情。但现在来看，似乎反过来事情也是可以成立的。就是说可以先小厂做一个事情，他他创造出来一个交互的创新或者产品的创新。那那做模型的公司也可以去借鉴或者应用，对吧？我觉得这点还是挺有意思的。

Speaker 2: 就是说很多时候大家会说比如模型做的越来越好了，感觉就是给这个创业公司做嫁衣了，对吧？因为你创造一个很好的模型，你如果没有自己运用特别好的话，那这些创业公司就已经用好了。但可以反过来说，比如如果你创造一个非常好的交互方式，但是你没有能力把他的这个模型能力或者底层能力做的特别好，那大公司也可以反过来借鉴你的这个交互方式，然后再加上他的模型能力，把这个事情做的也特别好，对吧？所以可能这个世界是个相互抄的关系，而不是一个单向超的关系。我个人的观点就是。

Speaker 1: 对如果你是 minus 的创始人 CEO 你今天要走向垂直方向吗？

Speaker 2: 我觉得 Venus 的一个价值就是说它给人一个非常尖锐的通用的感觉，对吧？但我觉得有一个非常通用的感觉的或者交互方式的 agent 和你有一些 get up 是不矛盾的。就是我觉得一个比较理想的情况是你有一个非常通用的交互方式，这个交互方式的上限或者说想象力可以足够大。就比如说 cursor 虽然他就就他是个 IDE 对吧？就是说如果他只做 IDE 的话，他想象空间是有上限的，就在 IDE 里面。但如果你做一个非常 general 的通用的产品形态，比如 minus，它显示空间上限是很高的。但是我觉得并不矛盾的事情是你能有一些每个阶段的 cuter p 比如说他做 PPT 特别好，或者做 deep 特别好，或者这个东西做的特别好。就有点像我觉得很多是伟大的产品都是这样的。

Speaker 2: 就是说 iphone 它是一个非常感觉让人非常通用的产品形态。但他一开始或者 ipad 他都有一些 killed APP 支持他有这个 montem 有这个增长的趋势，或者说包括 ChatGPT，包括包括阿东的微信。我觉得很多伟大的产品都是这样的。就是说你有一个足够通用或者简单或者低性的这样的交互方式，它有很多想象空间，但是你去维护它或者这个路径设计的时候，你能有各种各样的应用，能够使它能够不停的增长。

Speaker 1: 你觉得 deep sick 在过年这一波之后，对于你们对于硅谷的 AI researcher 有什么带来什么变化吗？叙事上的变化。

Speaker 2: 我觉得从 OpenAI 角度来说，我觉得大家好像讨论有有几点。一点是说 chain of salt 的这个 review。就是说显示这样的一个长的思维链似乎是一个很很重要的事情。就是它是一个产品形态上的突破。就是说很多时候这个世界就是像有很多技术的积累已经到了。就像一个洪水达到这个闸口，你需要一个时刻让这个东西发展，让让普通人，让大多数人能够感受到这个技术，对吧？

Speaker 2: 就是我们会说有 iphone moment，有 ChatGPT moment，然后可能有 dyp stic moment。然后这个 moment 可能就是说有一个非常大的这种交互方式的这种冲击。然后我觉得 x GPT 之所以。就 ChatGPT 本因为它的交互方式是一个非常新的，非常让人感到 magical 的这样的一个事情。然后我觉得 party 这个 dept c 之所以非常火，是因为就它的这个长长思维链给人的一种新的交互方式或者新的 magical 的体验。当然我觉得 deep sick 成功是一个非常复杂的，有很多原因的事情。但我觉得这是一点。

Speaker 2: 我觉得另一点就是重新思考开源。Sam 他在推特上也讲了很多，就是说这个事情就 open 了，就忽视了，但这个事情仔细想想看是有价值的，然后可能应该做的。我们就是默认的会认为开源会落后别人很多，对吧？

Speaker 2: 因为这个事情就是说不像 linux 像操作系统一样。就是说我有 1000 个人我可以每个人出一份力，我就可以使这个东西变得非常好。它有非常好的分布的性质，就是感觉造这个模型更像是我有 20 个特别厉害的人，然后我有很多很多钱，我只需要 20 个很强的人把这个事情做好就行。我需要一个非常特殊的组织，非常特殊的资源集中，非常特殊的人。那那这种情况下开源可能就传统的开源的优势并不大，对吧？然后包括像 facebook 可能开源做的没有那么好在美国可能大家就习惯性的忽视了这个事情。

Speaker 2: 从某种程度上来说，做好开源是一个很大 to view 的事情。因为首先你要有足够多资源，你要有很强的人，你要有个很好的组织文化，然后你还要有商业上的 justification。那那当然最好的情况就是你是个慈善家，你有几百亿，然后你就去做这个事情，造福世界。那这个事情是个很小概率事件，但是小概率事件发生就是这样一个人做的这样一个事情，我觉得这个事情还是值得反思，我觉得我也会思考。我觉得有很多包括组织架构，包括他的工程的，包括基础设施的，我觉得有很多值得称道的地方。

Speaker 1: 对，一个 AI 研究员想问你，他说他对 agent 的想象是有限的，所以希望你能畅想一下，以及你说你的终极理想是打造一个世界上最强的 agent 我看之前说过，你觉得他会是什么样的？

Speaker 2: 我什么时候。

Speaker 1: 说过你是在一个志远的访谈里说过支援。

Speaker 2: 社区 OK。对我觉得传统上或者说大多数人对 AGI 的想象就是一个模型，对吧？他就像这世界上最聪明的人一样，然后他拥有所有知识，拥有所有能力，他比我们都聪明，他是个最强的智能屏。

Speaker 2: 我现在的感觉可能是就不同的交互方式下有不同的好的定义，或者说有不同的强的边界。可能最终智能的边界是由不同的交互方式决定的，而不是一个 single 猫的决定的那从这角度来说，我觉得想象空间非常大。就现在大家只想要到做助手这件事情，让这个事情很明显有很大的想象空间，有很大的进步空间。还有很多没有诞生的交互方式，就像一开始互联网刚诞生的时候，可能最早 super f 就是说我把 mail 升级成 email 对吧？然后我把这个甚至就阿马斯已经是个非常创新的东西了，对吧？那那那我觉得现在就有点像那个时候，我们想象力还是被以往的交互方式所所限制了。这个东西我觉得很显然会创造很多种新的交互方式来改变我们的这个世界。

Speaker 1: 对你觉得最强的 A 阵的应该是什么样？还是没没想好。

Speaker 2: 我觉得对于不同的任务和交互方式，会需要不同的 agent 系统或者系统去解决。我现在的感觉是这样的，就是很多很大程度上这个模型是可以也许是可以 share 的。但是如果你讨论这样的一个系统的话，我觉得他会就像你问这个世界上最强的互联网网站，或者最强的互联网是什互联网的网站或者公司是什么？这事情很难回答对吧？因为它是一个 multiple ate，它是有很多不同面子的事情。

Speaker 2: 我觉得 AI 也是有可能变成这样的，就可能 open I 会成为一个 google，它会成为这个新的世界里面很重要的一环。但是我觉得并不代表这个世界就会被它不是单极，被这样一个单极的东西垄断。对我觉得这样的话，那那这个世界就会变得很灰暗，对吧？大多数人就没有什么价值了。

Speaker 1: 你对未来的 agent 生态的构想会是什么样呢？现在我觉得有点像当年大家都在创业做 APP 的那个时候，可能 11 年、一二年那个时候，如果再往后推几年，你觉得会是什么样？

Speaker 2: 这个世界我觉得很难说，对吧？但是我觉得肯定会有很多不同的交互方式创造出来不同的系统。就是说 open a 像 open a 这样的公司，他肯定会想继续推进这样一个中心化的助手一样的系统，然后有更多的环境，有更强的能力去做更多事情。那我觉得也会有不同的生态系统，然后有不同的交互方式，然后可能会训练完全不同的模型，可能甚至从他开始需要的能力或者很多东西是不一样的。就比如说也许另一种交互方式就是我想造一个我的朋友，那我的朋友可能不需要数学这么强，或者物理这么强，或者说他他数学这么强就反而有点假了，对吧？那他可能也不是记忆特别好，他可能也会出错，他有感情，他有他也不是特别 russian，那可能造这个东西也是有价值的那可能会有人做这个事情，那那可能那可能做这个事情你又很难去说他和 x GPT 哪更强对吧？因为它是不同的应用，它有不同的价值。那那也许有可能会有比如说一个 A 类的组成的社会，对吧？

Speaker 2: 就是说如果你认为中心化的极限是这个 context the limitation 的话，或者这么说，就为什么这个世界上有很多人有价值？并不是因为他的数学能力或者处理能力比别人强，是因为他有一些自己的信息，这个信息是他有别人没有的对吧？比如说有很多中间商，他本质上他就是拥有这个信息差，对吧？

Speaker 2: 那那拥有这个信息差的人，他还是会想去去维持自己的这个权利，或者维持自己的这个资源。也许这样的人他会发明出来一个更 multiple 或者更 disputed network，对吧？就比如说也许在交易的世界里面，这个信息是很重要的对吧？那每个人他可能只有拥有信息的一小部分，那这种情况下可能又会有新的不同的形态。它可能是一个 multi agent，就每个人我们有一个自己的 agent，然后 A 镇之间我可以 100 我和 100 万个人交换信息，或者去做交易，或者去去达成某些事情。那我觉得 fundamental 也就是说现在非常强的巨头，非常强的这些节点，它是有 motivation 去继续把这个事情变得更中心化的。但是不在这个中心化以外的这个力量，它也是有 motivation 去做一些非中心化的事情。对我觉得这个世界可能不会是一方超过另一方，我觉得两方都会有自己的力量，都会有自己的两种。

Speaker 1: 力量在博弈。

Speaker 2: 很有意思。

Speaker 1: 在你的脑海中的未来的世界还不是单极的，也不是中心化的。

Speaker 2: Again 就是我说的，就是可能会它变得更中心化和它变得更 diverse 并不矛盾，对吧？我觉得刚刚我们之前提到历史的这个演变有两个因素。一个是它的中心化程度或者贫富差距的拉大，另一个方面是我完成阶级跨越，或者我去从一个边缘到中心的这样一个速度或者可能性。但可能另一个另第三个性质就是说这个网络本身 diversity，或者它的复杂程度，或者它的这是多样性。那这个事情历史上来说也是越来越好的，对吧？就是说虽然世界上最大的公司对这个世界的经济的支配变得越来越强了，但世界上的产业总是越来越多了。这两个事情可以同时存在。

Speaker 1: 是更关键的。就是大模型技术没有垄断性，硅谷的头三四家好像都能追到一定的水平。如果欧派有垄断性，那是比较可怕的。

Speaker 2: 我觉得暂时没有垄断性，但是如果你能找到一个产品形态在那里面，就是研究的优势能够转化成商业优势，那就会产生壁垒。我觉得可能现在对于 XGP 来说，可能一个比较好的事情是 memory。我觉得这是一个可能产生必要的地方。因为如果没有 memory，那其实是在大家在拼谁的模型更强对吧？但有了 memory 之后，我拼的不仅是谁的模型更强，而是用户用哪个更多，哪个粘性更强。我在这里面有了更多积累的 context，他能够给我更好的体验之后，那我就会有这个粘性。那那可能是一种研究优势转化成商业优势的方式。

Speaker 1: 现在 XHPT 它会出现灰色提示词，说记忆更新吗？这个更新的到底是什么样？这就是你说的他增加年薪那种方式。

Speaker 2: 我其实最近没有怎么用 memory 这个 feature，但是好像最近就做了一些提升。我怀疑就是他产生或者使用积极的方式变得更好。对就包括可能他能够更有效的从很多的用户的对话中提炼出来，或者说 retrieve 就搜索出来更相关的东西。这个我不是特别了解细节。对，但是我觉得 intuitive ly 它是一个可能会产生粘性或者壁垒的一个东西。

Speaker 1: 你觉得 MCP 本质也是 memory 吗？因为我的很多的 context 是在我很多的个人软件，企业软件里头，那 MCP 本质也是 pack 我的 context 的一种方法。

Speaker 2: 我觉得从某种程度上来说，是的，就是说从某种程度上来说，这个世界有。很有一个 memory hierarch 对吧？就从一个 A 的角度。但是这个 memory hierarchy 最外层永远是环境，就有点像你考虑一个电脑？它有个 memory erotic，就是我从 CPU 的这个缓存到内存到这个硬盘。但是最外层的 memory 永远是这个外部世界的环境，对吧？就说比我插一个 U 盘，拔一个 U 盘，或者我把一个东西上传到互联网上，或者我就是做一个音乐，把它变成一个光盘，然后把它给对外部世界永远是 memory hierarchy 的最后面一层。

Speaker 2: 这个是我前年冬天我读了一本冯诺依曼死前写的最后一本书，叫做 the bring and computer。我觉得他写的我觉得最让我印象深刻的一句话就是说，essentially environment is always most out of part of the memory hierarch. 我觉得这个事情还是挺哲学的对。就对于人来说，就是说你有你的 memory hierarchy 对吧？你有你的 working memory，你有你的 memory 在脑子里面。但可能最外层的环，最外层的其实是比如你的笔记本，你的 google dog notion 这件事情相当于是你的最 long term 的 memory，或者说你的最外层的这个 my parking 的部分。

Speaker 1: 你觉得 long context 跟 long term memory 是一个什么样的关系？

Speaker 2: 我觉得 long contest 是一个实现 not of memory 的方式。就是说如果你能实现一亿或者 1000 亿或者无限长的 context，那它是实现 dot memory 的一种方式。它是一种和人区别很大的方式，但是这是有可能的对吧？就是说这是一种可能的方式。当然我觉得会有很多不同的方式，不好说哪一种是最好或者说最合适。

Speaker 1: 对现在业界实现 long context 有 linear 的方式，sparse 的方式或者 hybrid，你有倾向吗？

Speaker 2: 我不想对方法进行评论，但我想对 evacuation 和 task 进行评论。起码去年为止大家主要还在做的就是一些所谓的 long range arena。就是说 hey in the his stack，就是说我有一个非常长的东西，然后我在中间插入一句话，比如尧舜禹现在在 OpenAI，然后我去问你这个问题，我不想对方法进行评论，但我想对这任务进行评论。我觉得这是一个 necessary，但是不是 sufficient 的一个 task，就是你能完成这个 task，是个 not memory work 的前置条件，但它远远还没有到一个充分条件。我觉得它是个必要条件。但是我觉得现在大家有点陷入这个必要条件中，而没有创造更多更难或者更有价值的东西，我觉得这是一个问题。当你没有这样一个很好的评估的方式的时候，我觉得就很难讨论各种方式的好坏。

Speaker 1: 你的文章也说了，忽视了任务的本身的定义和评估标准的重要性。那你觉得应该怎么去定义和评估呢？比如说我们怎么去衡量一个 agent 你会有哪些北极星的指标？

Speaker 2: 还是要思考怎么去创造更多现实世界的价值。然后当然这个事情在不同的领域，在不同的应用下，会有非常不同的任务设计，有非常不同的方法，有非常不同的各种各样的东西。但是我觉得一个大的趋势就是说我们应该去更多思考实际价值，而不是这些被定义出来的类似于考试或者游戏的东西。因为我们发现一旦你可以定义考试或者一个游戏，那离他被解决也不远了。

Speaker 2: 真实世界之所以很难被解决，就是因为它不是一个被定义，或者被游戏，或者考试一个很大的一个特征。就是说它被设计的时候，它就有已经有了一个非常好设计好的 reward，或者一个非常设计好的答案。当你已经有一个非常好的设计好的 reward，或者一个非常设计好的答案的时候，那那那那你那你现在因为有了这个 g recipe，有了这样一个方法通用的方法，那离他被解决也不远了。在真实世界之所以很难被解决，就是因为它没有一个标准答案，它没有一个标准的 reward function。很多时候人做很多事情，他也没有办法去有一个 rational reward. 

Speaker 1: 但是人还是他是开放的对。

Speaker 2: 我觉得现在的主要的问题是这个，而不是说我有一个 well defind。比如说我有个 well defined 这个 answer，我怎么去找到他这个事情通过 R1 就已经可以做了。

Speaker 1: 你觉得我们未来还需要更多的推翻各种的基本的设定吗？

Speaker 2: 我觉得需要。就是从某种程度上来说，人类一直在做这个事情不是吗？就是最重要的事情往往就是推翻最基本的假设。可能我现在最关注的就一个假设，就是说一个东西的评估是基于比如说 500 个任务，这 500 个任务你分别跑 500 次，然后你把这些平行的这些数据加在一起，变成你的一个 reward。但这个我觉得是和人完全不一样，对吧？就是说人你在公司上班，重要的是你比如一天、30 天，一年之后变得有多好。而不是说我在 100 个平行宇宙把你放到这个公司，第一天你能做多好。我觉得这是一个基本假设的区别。

Speaker 1: 你感觉在竞赛环境下和实战环境下的区别是什么？因为也有一种说法说有些模型公司他会在竞赛环境下的奔驰码很高，但是实战不太行。有的模型公司就在实战环境下就比较好一些。

Speaker 2: 我觉得就是我们需要去更多的考虑一个东西的实际价值。因为大家发现我觉得我写的这个博客的另一个逻辑就是说大家发现刷榜实在太容易了，就是你总有办法把这个榜刷的很高。但是这样的话，有些东西的实际价值高，有些东西价值很低，这是一个问题。我觉得我们就需要有更好的评估方式。

Speaker 1: 你觉得 A 真的会迎来大爆发吗？

Speaker 2: 这几年我觉得会我觉得我们 2025 年或者 2024 年才终于有了这样一个通用的方法去做 agent。就是之前很多东西还不 ready，对吧？就是你要有很强的语言先验，你要有推理，你要有强化学习。然后我觉得这东西才刚刚被 unlock，才刚刚被解锁，有很多很多可以做的事情。

Speaker 1: 你觉得好的 AI 产品经理应该长什么样？

Speaker 2: 我觉得好的 AI 产品经理可能就是一个好的产品经理，并且可以第一性思考。因为 AI 是个变化很快的事情。但是我觉得可能不变的事情是相对更不变的事情，是人或者人性或者人的需求。我觉得这个可能是变化反而更慢的事情。我觉得就是说你能找到一个好的需求，然后你能从第一性原理反推，就是说把这事情做成。那我需要去应用什么样的技术，我觉得这个事情是比较重要的。

Speaker 1: 你听肖红的播客，你有什么感觉吗？

Speaker 2: 我觉得挺有意思的对，我印象最深刻的是他说 VC 是一个非常贵的融资方式，不是在你不好的时候，而是在你好的时候。我觉得这句话说的挺有意思。对我觉得我觉得他我觉得他有很多挺不一样的思考问题的角度，我觉得就是和 AI researcher，所以我觉得对我来说挺新鲜或者挺有意思。

Speaker 1: 你会考虑创业吗？

Speaker 2: 我觉得 OpenAI 可能大多数人都会考虑创业。因为现在是一个非常有三天的时候，而且现在已经有很多 open 人出去创业了，那我需要去做更有挑战的事情，那很自然就会去创业。但我觉得还是应该找到一个好的事情，我还是喜欢把事情想的清楚一点再去做。

Speaker 1: 你对未来 12 到 24 个月 agent 领域的有可能发生的有什么预期预测？

Speaker 2: 我觉得首先可能这些模型公司的 chatbot 系统会演化成一个很自然的 agent，它会是个很自然的过渡。就是说可能默认的比如说 clock 或者 chat BT 或者 anthropic cloud，它默认的这样的一个交互方式就会是一个 agenting 交互方式。我觉得 chat 可能还会保留或者作为一个子集，但是我觉得 A 正会会成为一个很显然更重要的交互方式。然后我觉得会有新的类似于 curse 的产品出现，curse 是在 coding 和 IDE 的这个环境下做了一个 copilot，但我觉得会有机会做一些新的环境或者更大的环境下的 co pilot。

Speaker 2: 然后这两种大的交互方式是互补的，或者说不一样的正交的。就一个是比如说我有一个基于模型的，然后可能是一个 remote 的 virtual machine 或者一个 environment，然后在里面做很多事情。然后另一边是有很多既有的环境，比如说既有的这些软件或者既有的这些场景。然后我就把 agent 或者 AI 的能力引进去。我觉得就大趋势可能就这两个方面都会发生。所以说就类似于 David 或者类似于科 sir 的事情，我觉得都会都会往下发展。

Speaker 1: 如果我们想推动 agented 能力变得更强，是要在哪里做工作呢？是在 pretrail 做工作呢？R 做工作呢？如果我是一个应用创业者，那我这两个东西是做不了的，最多尝试一些端到端的 L 的一些过程，对吧？

Speaker 2: 对我觉得可能最重要的事情还是想清楚价值，就想清楚你的应用的价值是什么，就是你的痛点是什么，你要解决的问题是什么。然后我觉得可能虽然你可能不能做 p training 或者不能做 training，但是我觉得可能更有价值的点是一个是 agent 和数字世界的交互的环境是什么样的。就它是基于 MCP 还是 API 还是一些别的东西的。另一个是人和这个 A 正交互的方式是什么样的这两个事情是你可以去做，并且它需要很多设计，需要很多 infrared，需要很多工程，需要很多各种各样的东西。它我觉得现在做的还远远不够好，还有很多进步的空间。我觉得可能还有另一个很重要的事情，就是说怎么去构建一个生态系统，或者怎么去构建积累优秀的 intention，或者用户的这种 context 或者 intention。然后我觉得这个事情还有很多可以做的空间。

Speaker 1: 你刚才提到了 agent info 相关的那如果说两年后 agent 已经大爆发了，巨量的 agents 在这个数字世界运行。那你感觉 agent 需要重新帮他设计一套新的数字化系统？Agent 需要的虚拟机、电脑浏览器搜索的 API 身份认证经济系统等等等等。这套 info 是为 agent 设计的，而不是完全为人设计的。

Speaker 2: 我个人感觉可能两年以内，这个世界可能还不会变得这么分布式，可能还是会更偏中心化。就是说会有一些 super APP。就比如说现在当然 AI 有很多创业公司对吧，但是做的好的就是那么几家对吧？我觉得可能两年内还是会有些 super APP。然后这些 super APP 会有各自的 info，有各自的这些。

Speaker 2: Environment 或者交互方式，就是两个事情都可以做到极致。一个是基于用户 local 的这些 digital environment。比如说我有一个手机，我有个电脑，我有一个软件，我已经在这了，我怎么把它去扩充，怎么把它就变得更好。另一个事情是从头撞到创造新的一个？比如说我做 deep research 或者我做 Operator，我实际上创造一个新的 environment。我觉得这两个事情都还有很多可做的空间。

Speaker 1: 两年后我觉得没有人。

Speaker 2: 能看到两年以后这个世界就是变化很大。我觉得你能有一些像科幻一样的预测或者想法，或者你的图景，但是很难说。对我觉得没有人可以预测两年以后发生什么。

Speaker 1: 你在 offer 的一个好处是不是？你可以知道有哪些事情是他的主赛道，就是他一定会做的。然后有有哪些事情可能是创业公司机会，你会有这样的感知吗？

Speaker 2: 我觉得就是每个公司一旦他有他的 super APP 之后，他的所有事情会围绕它的 super APP。就是当你比如说有 XGBD 之后，那你训练模型的方式，包括组织架构，包括很多事情都会围绕这个 chat BT 去去重构，对吧？我觉得如果你做一个和 ChatGPT 形态很不一样的东西，还是会有机会的。

Speaker 1: By the way， 为什么你的文章叫 second half？为什么现在是中场呢？

Speaker 2: 因为我觉得就是从方法论上，我们刚刚实现了一个基点一样的时刻。就是说我们终于有一个非常通用的方法，就可以去解决各种各样的事情。如果你问一个十年前的 AI research，那他会认为比如说去做翻译和去用去玩游戏，和用电脑去订票，和去做数学是完全不同的事情。他需要的他需要方法完全不同，他需要的这人完全不同，他是完全不同的社区，对吧？他们开完全不同的会有完全不同的 paper 是没有关系的这些事情。但现在终于这些事情都用一个方法可以解决了。你这是一个本质性的方法论上的基点事件。

Speaker 1: 你是放在一个更长的人工智能的历史里面来说的，并不是说就这一两年的一个事儿。

Speaker 2: 我觉得是的，天下大事就是分久必合，合久必分，对吧？我觉得就是大家已经分的太久了。一个做回答问题的 researcher 和一个做写代码的 researcher，他可能五年前没有完全没有任何沟通，因为这两个事情完全不一样。现在这个事情可能就一个事情就非常不恰当的比喻，就有点像物理里面，就比如牛顿力学突然被提出来，就是我们发现这个世界其实可以用一个统一的方法去理解了。现在感觉就是我们意识到这个世界上很多问题是可以用的统一方法去解决的那我觉得这是一个本质的不一样的事情。

Speaker 2: 之前有很多伟大的事情是在为这个事情做铺垫，对吧？我觉得 transformer 是个很伟大的事情，也是很伟大的事情，有很多很伟大的事情。但是这些很伟大的事情最后导致了这样的一个事件的发生。就像牛顿之前有很多很伟大的事情为他做铺垫，就是说开普勒市值价值是多的，就有各种各样的事情都很伟大，但是他们最终导致了牛顿力学。但是这样一个我觉得物理里面可以说几点性的事件，吧？

Speaker 1: 你觉得 pre training 是为强化学习做铺垫，还是为 A 镇做铺垫？

Speaker 2: A 真的是我们想要实现的事情，对吧？然后他和 RL 都是实现这个东西需要的技术的一部分。当然你也可以说就是 presenting VR 要做的铺垫，因为如果没有 present，你很难在这些基于文字的环境里面去做，我觉得这是一个很很 long review 的事情。对，因为传统上 21 的人并不 care about prior，他不并不 care about 的或者先验知识。就是他认为我有一个环境，我有 reward，那 is a matter of time，is a matter of samples that I can solve the environment. 

Speaker 2: 就是说我可以理论上证明，就即使是一个比如互联网，即使我没有这个 presence，我只要有足够多的 sample，我还是可以去用暴力解决这个问题。只要你把 reward 定义足够好，并且我的 training 和 test reward 是 same distribution。但可能就是说这个的 sample 量或者他可能要需要学，比如十的 30 次方年，可能就他永远学不会。就在宇宙年龄的意义上来说，对吧？那从这个事情上来说，我觉得 pretty 他为了这些基于语言的 21 去奠定了基础。没有这个事情，你永远说你还是可以做，但是实际上你做不了。

Speaker 1: 你觉得科技公司应该重新开启 pre training 的趋势吗？这是上一次广觅的博客里面的一个很重要的观点，就是一个非非共识，应该重新重视。Free training. 

Speaker 2: 这里面有一个 cost 和 value 的取舍，对吧？这是之所以现在做的人很少，是因为它的 cos 非常大，但它好像带来的 additional value 并没有那么大。因为我可以用这个开源模型或者 API，我好像并没有一个就好像是一个一边倒的局势，对吧？就是我 cause 也非常大，但我也没有什么特别大的价值的新增。因为你做完 pressure 你还要去做 postion，你还要去做很多事情，你才能把这个 pressure 价值体现出来。但是我觉得如果有一天，就像我说的，就是说这个世界有很多不同的 super APP，有很多不同的交互方式。它需要不完全不同的模型能力或者不同的模型，然后这些东西的价值足够 justify pressing the cost，那我觉得它就会合理。我觉得是一个 value 和 cost 的关系。

Speaker 1: 所以你刚才提到分久必合，合久必分。你感觉 petrogal 跟 R 未来的关系或者怎么样？就是会不会更多的先验知识会放到 petroc 里头呢？

Speaker 2: 我的一个不成熟的想法是可能会有不同的应用需要不同形态的 agent 那它可能构造的方式是不一样的，对吧？就是说比如说假设我只要下围棋，那我就直接做阿尔法狗就行了。我不需要不是事情，我不需要做任何事情。如果我有个非常垂直的垂类，这个东西价值足够大，然后我有很多数据我可以形成闭环，那我也许就主要是 RL 的主要基于 RL 的一个东西就可以 work。从某种程度上来说，我觉得像 google 的 S 或者 tiktok 的推荐，从某种程度来说就有点像类似于这样的一个系统对吧？结果找到一个足够封闭的环境，我就是做类似于 R1 的事情，我就可以带来足够多价值。那这个事情是合理的。

Speaker 2: 但可能这个世界上很多长尾的事情，他需要 genius ation，他需要去搭建一个像人一样的东西。就是说你虽然不是什么都知道，但是你可以学，你可以通过在线学习，你可以去进入一个新的公司，然后适应这个环境去做一些新的事情。那在这个地方可能 pretty 的重要性会更高。因为你需要更多的泛化性。所以我觉得可能基于不同的应用会有不同的技术路线。但是我觉得技术路线毕竟是个工具，就是你只要你的 V 六大于你的 cos 就是我觉得技术的选择是 flexibility，没有说一定会哪种技术路线会胜出。我觉得只要经济上的合理，它就是有可能性。

Speaker 1: 如果你是一个全球超大互联网或科技公司的 CEO，而今天这个公司还没有自己的模型，没有好的 research 的文化，甚至没有好的 AI 战略，你作为 CEO 你会怎么做？

Speaker 2: 我觉得我会首先我肯定会学习，对吧？就是说我很想学习这个事情到底是什么。因为如果你作为 CEO 你不懂这个事情，那所有事情都很难。我觉得很多时候一个公司他的 boss next 就是说 CEO 对这个事情的理解程度。如果你不理解这个，然后你说我去招一些很好的人我去做些事情，那你可能会被他们忽悠的。

Speaker 2: 就是我觉得首先你自己要学习，然后我觉得还是要从创造新的价值来思考问题。因为毕竟你不是技术专家，你是一个公司的 CEO，然后你有一些场景，你有些资源，你有些优势，然后我觉得从第一性原理来说，就是一个新的技术产生了。那那你需要思考的是怎么用这些新的技术和你现在的资源去创造新的价值。当然你可以试图去做一个和现在业务完全不一样，然后价值非常大的东西，比如插 GPT。但是可能对大多数，即使是很有钱很厉害的公司来说，这个事情并不 make sense。首先自己要学习这个技术。然后第二是我觉得你要去思考就是能创造什么新的价值。

Speaker 1: 如果你成为了伯克希尔的 CEO，未来要拿出 500 亿美金 allocate 到 AGI 这个行业，你会怎么去 allocate 这笔钱？既能体现回报，也能体现对人类的贡献。

Speaker 2: 这是个很好的问题。然后这取决于你有多少精力，或者有多少的资源分配的颗粒度，对吧？当然我觉得现在像 open I topic 就这些模型层的公司是会有价值的，我觉得是会有更大价值的。大概率来说，我觉得其实还有一类很有价值的事情，是能够积累 user context，或者能构建特殊的 environment 这样的一个公司。就因为最终我觉得 AAI 或者 AGI 是个系统的话，它需要用 intelligence，它需要有环境，它还是需要有 user 的 context 或者对 using understanding。

Speaker 2: 现在可能我觉得有很多 user data，或者有很多优秀 contest 的公司，就有点像发明车之前的煤炭煤矿。可能当时煤矿已经有可能发明汽车之前的石油公司对吧？就是当时可能也许也有一些小的应用或者怎么样，但是我觉得现在大家对于这个东西的应用还没有足够大，可能会有一些机会。

Speaker 2: 然后从这程度来说，我觉得微信或者。就像这些大的平台，它还是一个很好的易守难攻的好的平台，对吧？因为它积攒大量的 context。然后如果 intelligence 它是一个可以逐渐民主化，逐渐变得便宜，逐渐变得普及的一个东西的话。那拥有这样的平台，拥有这样的一个 environment，拥有这样一个 context，可能会是一个很强的壁垒。所以他可能还是一个很好的投资。我觉得。

Speaker 1: 今天顺宇当了很多公司的 CEO，我再问一个，如果你是微信的老板，你会怎么在微信里做 agent？

Speaker 2: 我觉得我可能会不急，我可能先观望，就是我好像没有理由要急。然后我会观察，我会学习对吧？我会学习 AI 然后我会观察有没有什么新的交互方式，很有意思。但是我觉得我不会急着去做很多事情，因为我是一个我有个易守难攻的地方，我为什么要急着进攻？

Speaker 2: 可能比较危险的事情是一个颠覆性的创新，对吧？就可能我觉得真正的危险不是说一个类似于微信东西打败了微信，而是一个很不一样的东西打败了微信，就是像微信打败了 QQ 一样。就 Q 可能当时担心的并不是一个类似 QQ 的东西打不了 QQ，而是一个很不一样的产品去打败了这个东西。我觉得可能我觉得需要对颠覆性的创新有所警惕。对但如果是这些 incremental 的创新，就是这种小的创新，那我觉得你早做晚做可能区别没有那么大，也不用太担心。

Speaker 1: 因为所有人都说微信卡位好，但今天微信还没有很激进的投入。那如果未来 multi agents 这些 long term memory 这些问题解决了，但这个 agent 系统不长在微信上，那是比较恐怖的。其实原有的网络不一定有价值。

Speaker 2: 就是我觉得这取决于人的这个网络，人类的这个网络会变成什么样，对吧？就是说你会有更多的 agent 朋友，还是有更多的人类朋友，或者你有更多的 agent 的这个职业上的交互，还是有更多人类的职业上交互。因为微信上你既有朋友也有，比如我要买买个东西，或者我要咨询一个东西，或者我要律师或者就这些。基于职业的交互。我觉得这个取决于人类的网络会变成什么样。但我觉得总会有一个这样的网络，然后基于这个网络肯定会需要有基础设施，需要有平台。

Speaker 1: 怎么保证 AGI 实现之后的安全问题？因为微信过去还是一个比较负责任，比较安全的那如果未来 power 很强了，很多坏人来做坏事了，甚至颠覆人类了，那安全问题你觉得长期会怎么解决？要有 AI 宪法。

Speaker 2: 我觉得安全是一个很复杂的问题，就是当每个人说安全的时候，其实他可能想的事情也不一样。我的看法是这样的，我就现在大家对安全的主要分歧就是说像商业公司一样，正常的重视安全是不是足够的，还是说你需要有更大的安全的责任，吧？因为比如对 XGP 来说，如果他不安全，他把你的东西删了，或者他那他这个产品就失败了，他没有商业价值。所以即使为了商业价值，他也会去重视很多安全，对吧？就每个产品都是这样的，他会基于自己的产品和商业，他自然而然会重视安全。因为这个东西如果不安全，那它根本就不是个好产品，那人们不会用它它没有价值。

Speaker 2: 但我觉得现在主要是大家对这个东西分歧是你需不需要产品以外的，或者说更意识形态上的这种安全，或者说对，但这个事情我觉得大家还没有完全的定义清楚。然后我觉得前者是容易解决的。就是如果你有一个好的应用，然后你有一个你总是会有办法去解决安全问题的。我相信因为一旦一个东西有足够大的价值，那总会有人需要解决这个安全问题。因为如果解决这个安全问题是带来价值的一个必要条件，这东西价值有足够大，那我觉得它总是会被解决了。但我觉得至于第二个我觉得会有很大的不确定性，我觉得我很难评价对。

Speaker 1: 一个人会担心 AGI 事件之后的安全问题吗？

Speaker 2: 我会担心，但是我觉得现在可能最大的问题是 AGI 还没有实现，或者说我们还没有创造足够的价值。我觉得一个东西如果还没有创造足够的价值，就担心他是不是太太厉害，或者太强大，或者太普及了。我觉得好像不是特别 make sense。如果我们还没有想清楚对怎么把这个东西变得有价值，那那我们把它变得很安全好像没有意义。因为它如果没有价值，它很安全似乎也没有意义。

Speaker 1: 从机器原理的角度来说，模型到底会不会产生意识？

Speaker 2: 我觉得意识是一个没有被很好定义的东西。但是我觉得也许当你能够处理足够复杂的 context，并且你有足够大的 autonomic y 或者 decision making the power，那那客观上你可能就产生意识了，对吧？之所以我们认为我们有意识，是因为我们在一个自己认为很高的频率在处理信息，在不停的处理信息做决策。然后脑子里面闪过各种各样的想法，然后我可以选择做很多不同的事情，然后他会有不同的后果。那是不是客观上来说，如果一个系统能做到这些，它就可以被定义为有意识的。我觉得这个事情还没有被很好的定义。

Speaker 1: 对你说现在要定义任务，定义问题吗？你现在思考的比较多的几个非常重要的问题是什么？

Speaker 2: 我其实对很多问题都很感兴趣，但是我不可能做所有问题。但我会试图和很多有意思的人聊天，然后试图去理解有什么事情在发生的。

Speaker 1: 你最近思考比较多的问题有什么？你最近有什么顿悟时刻吗？

Speaker 2: 比如说过去一年我觉得一个 inside，就是说可能这个世界会有很多这个技术可能是比现在的产品形态更更通用的，就是可能会有更多 super APP 出现。我觉得这个事情是有机会的，我觉得还有很多小的顿悟。但是我觉得大的顿悟可能就是说这个世界可能会有更多交互方式上的创新，带来新的 super APP。这个世界研究的边界可能不是一个一家机构定义的，而是可能不同的 super APP 共同经营的。

Speaker 1: 你的文章真的是基于 deep research，基于你的演讲稿写的吗？

Speaker 2: 是的，但是我就是那个 introduction，我基本上就是改的比较小，但是可能后面有些段落我基本上就删掉重写了。对，因为我觉得这个东西它解决的问题是一个 initial ization 的问题。就是说它给了你一个初始化，然后这个初始化能够如果能够让你进入一个清流，那你其实自己重新写一遍也不是很难了。但是我觉得重要的是它能初始化你的这个 money flow，初始化你的心流。但如果你能进入一个心流，你其实重新写和改没有区别，或者可能重新写会更快。

Speaker 1: 你重新写了多久？

Speaker 2: 可能 2 个小时。

Speaker 1: 你作为 every session，其实在博士期间的很多工作就已经获得了很多的关注。你觉得为什么？你觉得你做对了什么呢？

Speaker 2: 我想做的事情就是就两条线，一个是简单通用的方法，另一个是跟不同的有实际价值的任务。然后这些任务往往就是如何在真实的数字世界创造新的价值。因为传统的任务就是要不然就是在虚假的数字世界，比如游戏或者考试里面创造任务，或者是在物理世界创造价值。那我觉得可能真实的数字世界，比如电脑或者 coding，或者 web 是一个处女地，就是一个巨大的宝藏。然后我恰好挖掘了一些东西，然后这个 GBT3 的产生或者这些模型的产生，推理的产生又有一个机会，就是能做一些简单通用的方法。但是我觉得也是有一些时代的原因。

Speaker 2: 对，就是恰好有这样的一些机会，然后恰好这些东西我觉得是对 AI 最重要的事情。就是一方面是简单通用方法，一方面是更好的任务环境。然后我觉得需要然后我觉得需要就是想的足够大胆或者通用。对，如果你再做个上限很低的任务，那你就算把它解决了又能怎么样？我觉得需要做一些很现在看上去很难的任务，并且我觉得可能另一个很重要的点是要去看很多东西的交界处。就说如果你只做 RL 或者只做如果你只做强化学习，或者你只做自然语言处理，或者你只做一个学科的内部的东西，那那我觉得可能会很难。

Speaker 2: 我觉得 react 之所以当时能做出来，是因为就我们当时选了一些自然语言处理的 task，我们也选了一些游戏的任务。你需要把自然语言处理和强化学习的边界也给打通。但我觉得可能很多人他会陷入一个社区，或者陷入一个学科内部，这样的话就会更难去做一些更通用的东西。

Speaker 1: React 当时在做的过程中有积累，什么弄好吗？有遇到什么坎吗？

Speaker 2: 我觉得最难的是寻找任务，我觉得所有我做的任务就方法性的我做所有方法。其实我觉得最难的事情都是找任务。因为我觉得很显然就是说有一天这样的一个事情会变得非常有价值，对吧？就是一个智能体既能够推理又可以做动作。但我觉得真正难的点是在当时的环境下，比如你当时只有一个 GPT3 或者一个 pom 然后你又没有你怎么去找一些他任务，能够去证明这个东西有 promising 的 initial signal，能有好的价值。然后这个东西我觉得其实试了很久，包括我觉得做 true 最难的一点，也是你怎么去把这样的一个 belief 寻找一个任务，或者寻找一个环境，去通过实验结果表达出来。

Speaker 1: 你现在能定义的最激进的一个任务可能会是什么样？

Speaker 2: 我先我前面一个这个问题我可以先补充一点，就是因为我觉得我的经历可能比较特殊。因为大多数好的方法提升提出是因为它有一个特定的任务。然后这个特定的任务恰好激发出来一个非常通用的方法，比如说 PPO 可能一开始是做一个特定的事情，或者 transworld 一开始是做一个特定的事情。比如我觉得就是 attention 的一类工作，其实是受翻译这件事情的影响很深的。如果当时那个时间点你恰好在做翻译，然后那你就很有可能就做出了伟大的东西。因为恰好那个时候如果注意机制，最适合研究他的任务就是一个翻译一样的事情。因为他需要自然的对这个序列的不同地方进行关注，然后这个关注可能不是现行的，然后他需要一个类似传销的这样的一个方法。所以大多数时候人们发现伟大的方法是因为你有一个任务你要解决它，然后恰好这个事情足够通用。

Speaker 2: 但我觉得就我的经历比较特殊，是因为很多时候我是先脑子里想到一个东西，我觉得它很通用很好，但是我需要去找一些任务去证明它很通用、很好，或者未来会很有价值。他可能现在还没有足够多价值，但是你需要现在先找一些简单的任务去去去证明它有价值。我觉得这个事情是很难的，就像创业需要有这个 prod market fit 一样，就是作者确实需要一个 method task fit。这个世界是最难的。

Speaker 1: 你得先感想，那你最激进的想一个定一个任务会是什么样呢？通用人物。

Speaker 2: 我觉得现在这个时代可能再再激进也不叫激进，就是我觉得 anything is possible。我毕业前我可能想的比较多的事情是怎么去创造一个爱因斯坦，或者怎么去创造一个科学家。因为我觉得当时我还是一个比较阿克迪米亚的，就比较学术圈的一个人，对吧？就是说你在普林斯顿，你自然你的偶像是冯诺依曼，是爱因斯坦。那很自然。

Speaker 2: 我觉得能想到的就是说最有意思的 task 就是说我能不能发现下一个相对论，我能不能发现下一个伟大的科学理论。我觉得这个事情毫无疑问能够标志人类 AGI 或者 ASI 实现了，对吧？如果 AI 发现了大一统理论，我觉得到了硅谷，到了加州之后，就是进入了公司之后，我觉得人类的组织也是一个很有意思的事情。然后我觉得如果能够创造一家新的公司，能够创造一个 one dollar 的基于 H 的公司，我觉得是很有意思的事情，就创造经济价值也很难。他和发明相对论是不一样的。

Speaker 1: 为什么是人类的组织也很有意思，而不是人类的产品很有意思。

Speaker 2: 产品当然很有意思，但是很有意思的是很多组织的方式能够它就像一个 general method，一个像一个通用方法一样。它能够去帮助创造很多不一样的伟大的东西，对吧？就是说比如股份制或者这样的一些机制设计，或者一些组织架构，它就像一个非常通用的 AI 方法一样，就是它它导致了很多不一样的伟大的东西出现，对吧？我觉得这个事情本身也很有意思。

Speaker 1: 为什么在就我们刚才说的那个 open I 的五个分级的最后，他是组织者。

Speaker 2: 我其实一开始我是认为 innovator 和 organization 是一个更正交或者并列或者。我当时在群里问了一个问题，为什么？比如说当一个大公司的 CEO 和当一个科学家到底哪一个难？我觉得这个不好说对吧？而且你可能实现的 research 的路径是有区别的，我觉得都很重要，我觉得不用太纠结谁是第四集，谁是第五集，我觉得都很重要。但是我不觉得一定要先实现哪一个才能实现另一个我觉得可以同时去探索。对。

Speaker 1: 在你的成长路上，你觉得你的自己的 my site 跟你的同龄人差不多吗？还是不一样。

Speaker 2: 我觉得有一样的地方，也有不一样的地方。就是我觉得其实我的路径还是挺按部就班的。就是我也没有跳级，我也没有大环境下大家都去美国读博了，我也去美国读博了，然后我感觉没有做什么很很 surprising 的事情。但是我觉得我对一个东西的价值或者 taste 有有自己的看法。

Speaker 2: 就是我觉得一个东西，我觉得大家往往会倾向于去做一个确定性比较高的事情，或者说就包括做 research，包括做公司，包括做任何事情。但我觉得恰好是这个时代，我觉得可能你去做上限更高的事情是更好的，因为有一个巨大的机会。对，如果没有一个这样巨大的机会，那可能最佳的路径可能就是去做 incremental 的事情，去做确定性强的事情。要一步一步积累，但是恰好有一个上限非常高的事情。那那如果你敢敢想，或者你胆子特别大，或者你想象力很丰富，那就会有好的事情发生。我觉得在你。

Speaker 1: 成长路上对你启发大的是什么？是书，是电影，是音乐剧，行车你这些 my site. 

Speaker 2: 我觉得看书还是挺有帮助的。我是一个喜欢看杂书的人，就是我什么书都看我觉得这个还是挺有帮助的。我什么电影都看，然后什么地方都想去。就是我我感觉我从小是一个比较尖锐的人，我想我想试图变得很通用，我也想试图去了解很多不同的学科，然后去做很多不同的事情。但后来我就发现，一个人即使再聪明，再有精力，他能理解的知识或者能做的事情也只是人类社会积累的知识的很小一部分。可能更好的一个事情就是说你去创造一个比你更通用更尖锐的事情。我觉得我好像一直有一个对于这种通用性的一种执念，或者追求的通用。

Speaker 1: 性能带来什么呢？通用性意味着什么呢？因为它可以足够简单。

Speaker 2: 我不知道，但是我觉得我从小就是想学习很多不同的学科，就是我觉得都很有意思，很多就是我在摇摆，很多同学我觉得他们是那种很很 deep 很 focus 的东西，对吧？就是说我去做竞赛，我就把这个事情做到极致，我就不停的刷题，我把我做到了世界金牌。但我觉得我好像不是那种性格，我是那种我会看很多数学，但我也会看很多历史，我会看很多各种各样乱七八糟的东西。

Speaker 1: 对你会刷竞赛吗？

Speaker 2: 我也搞了竞赛，但是我没有我的本科同学那么厉害。我最后是心医学到全国银鹏。

Speaker 1: 你还是清华的说唱社联合创始人，对吧？我昨天去翻了一下你的网易云音乐，你的那个歌。

Speaker 2: 被被你找到了。你看来你有 deep reception 的能力。

Speaker 1: 你最最喜欢的说唱的 star 是谁啊？

Speaker 2: interesting。我有很多喜欢的说唱歌手，我觉得说唱我觉得很有意思，就是因为每个人风格都很不一样，然后没有一个有点雯文无第一，武无第二的感觉，对吧？就是说每个人都有自己很独特的东西，所以它能体现很多价值。我觉得这点是很多人喜欢说唱的原因。就是你有自己的个性，你有自己的 flow，你有自己的生活的思考，你可以创造出来不一样的东西。它不一定是最好的东西，当然是不一样的东西。我觉得这点是很吸引人的。

Speaker 1: 他跟你深 A 有什么相似的地方呢？他给你做 A. 

Speaker 2: I 挺有意思的。就是我觉得我记得 gbt 3 刚出来的时候，大家都觉得很厉害。然后我当时想到第一个做的事情就是说看能不能生成押韵的说唱歌词，并且有内容性。我发现这事情还是很难，似乎今天还是很难，也许说明说唱歌手是一个被人们低估的工作。对。

Speaker 1: 为什么难呢？因为填词儿，他这不就是 predict token 要做的事情吗？

Speaker 2: 我觉得首先一个东西好听或者 flow 好，或者听上去舒服，是一个很难被量化的 reward。但是我觉得独特的 flow 或者这个事情是很难量化的 reward 很多时候一个东西，比如这个节奏和这个 flow，或者这个 style 它出现太多了，那它就不好了。独特反而是好的，这个声音是很难被量化的。review. 我第二点就是说真正伟大的说唱歌手，他他他有他的很多独特的对生活的思考。我觉得这一点好像似乎 AI 还做不到，因为他们还没有生活。

Speaker 1: 有可能能有比语言让智能更通用的东西吗？

Speaker 2: 我觉得不同的在一个特定的领域肯定会有比语言更好的表现。比如说在围棋里面，你用自然语言思考可能就不是最优的方法，对吧？但我觉得语言诞生，它不是为了处理某个特定任务的这个效率或者交流。他为的是能够打通所有任务，或者打通人的这些认知能力，然后形成一个通用的这样的一个表示。所以它并不是为了某个特定的任务的最优而优化的。往往就是说你会发现它在某个特定任务上它有很多冗余性，但是它整体上是一个通用的东西。然后当然就是说就像我们可以创造一个新的语言一样，AI 当然也可以创造一个新的语言，它可能效率更高或者怎么样。但是我觉得可能最终大概率就是英语或者基于英语还是会成为一个主流的语言。

Speaker 2: 因为人类已经有一个这样很强的 prior，有个很强的先验知识，而且人有这样的价值的取向或者 motivation。他有这个动机会想让机器的语言和人更像这样我们可以更好的去理解他，控制它、监控它、改变它、操控它。那那似乎它是个很自然的选择。

Speaker 1: 你的内心驱动力是什么样？你的愿景是什么样？你十年后想成为谁呢？

Speaker 2: 我觉得。我还是想用一个非常俗的话来说，就是你希望你希望你对这个世界创造的一些不同，对吧？我觉得如果能探索新的根本性的研究，是一种创造不同的方式，或者你能创造一种完全不同的新的产品形态。在大家如果都在做同样的事情的时候，你做一些不一样的事情，我觉得这个会比较有意思。就是我觉得比如说你现在去做一家类似于 XAI 或者 thinking machine，就是说我再去做一个类似于 chatbot 或者 assistant 的这样的一个 AI 公司，那我觉得还是很有可能赚很多钱，商业上很成功。但是比如说如果我作为一个形态很不一样的东西，但是失败了，但是我觉得我起码探索了一种不一样的东西，我觉得会更有意思吧，我觉得。

Speaker 2: 我想对上一点进行一个补充。就是我我觉得我导师对我印象最深或者印象最深的一句话就是说他我们会讨论。比如说我们有学术圈很经常发生的一个事情，就是说你有一个想法，然后别人做那你就会很烦。然后他就会说 if someone else can do IT，then it's OK to let them do IT. 

Speaker 2: 如果你从人类全局的角度来说，如果这个事情很多人都能做，然后那那别人做的可能是不是也没有什么区别。对这个社会或者对这个整体来说似乎没有什么变化。如果你的当然我记得就是说我我我有提到这件事情，然后有人说这个非常假。因为最终你会发现这个世上没有什么事情是不可替代的对吧？相对论其实没有被提出，也会有人提出，对吧？就是没有什么事情是你死了或者你不在另一个人不能提出了。

Speaker 2: 但是但是我觉得这个话还是有道理的对，如果你很清楚的能看到，别人就在做这个事情，或者别人就在就类似于做这样的事情，那你可以选择去和她卷。我觉得如果你要和她去卷，那你认为比如你会更有效率，或者你能把这个事情做得更好，那我觉得这也是合理的。但是或者你去做一些不一样的事情去探索，我觉得就是最终你要对这个社会产生价值。然后在这个时代，我觉得很幸运的一点就是说这个技术非常通用，这个是技术非常伟大，我觉得有足够多探索的空间。那那我觉得比如说 coding 是一个非常显然大家都在做的事情。那那也许我的价值就是说我把这个最初始的 initial signal 给摘出来。如果别人能做，我觉得别人做也是 OK 的。然后另一点我觉得可能就是说你想要让自己的生活变得更有趣，或者更有意思，或者更更快乐，那那你就去做一些让自己喜欢的事情。但这个事情就很难用语言解释，就是一个 taste 或者是一个 preference 的问题。

Speaker 1: 你会对 agent 的创业者有什么建议吗？

Speaker 2: 我觉得这个我已经说了很多遍，可能有点老套。但是我觉得就是想清楚你的价值是什么。我觉得技术是个工具，当然理解技术的趋势很重要。但是我觉得创造价值是最重要的。或者想清楚你为你的用户带来了什么样的增加价值，这是最重要。

Speaker 1: 你最近坚持了你自己的 taste 做的一件 batt 是什么？

Speaker 2: 希望你们能看到，i'm doing something。

Speaker 1: 我最后几个快问快答，一个全球范围内你喜欢的食物。

Speaker 2: 我喜欢椰子。

Speaker 1: 一个全球范围内你喜欢的地点。

Speaker 2: 我很喜欢伊斯坦布尔。

Speaker 1: 一个少有人知道但是必须知道的知识点。

Speaker 2: 我挺建议大家去看智能简史这本书的，我觉得有很多很有意思的知识点。比如说为什么大多数动物都是左右两侧对称，并且有一个像嘴一样的食物入口，有一个像肛门一样的这样的食物的出口。然后为什么气体是同一个口，而食物是和水是两个口？这个事情很有意思，就是它是有些本质原因。

Speaker 1: 什么本质原因？

Speaker 2: 比如说你会发现如果你要去做 navigation，你要对这个世界你在这个世界中移动左右对称的结构是最优的。就像你发现世界上所有交通工具都是左右对称的。因为你可以一个方向进行前进后退，另一个方向向左转向右转。他和车和飞机是左右对称的，结构是类似。然后至于食物和这个气体还有别的原因的。

Speaker 1: 借你所有读过的书推荐两本必读书。

Speaker 2: 我觉得智能简史这本书很有意思，我去了去年读，我觉得很有意思。然后我会推荐各种各样的自传。我觉得传记很有意思，就好像是你在读别人的生活一样的，在体验别人生活。

Speaker 1: 你心目中影响 AI 进程的几篇论文。

Speaker 2: 我觉得有很多。

Speaker 1: 如果是最我觉得。

Speaker 2: 没有罪，这些东西都是一个积累的过程。然后 book prop 然后 transformer GPT 我觉得是一个积累的过程，我觉得没有一个是最伟大的工作。对。

Speaker 1: 基于你当下的认知，一个最关键的重要的 bat 是什么？

Speaker 2: 就是带有 different super APP 的产品形态，有不同的交互方式。如果你不相信这一点的话，那这个世界就变得很灰暗。只有 open a 或者 topic 有机会。但是如果你相信这一点的话，就会有很多新的机会。

Speaker 1: 你的 MBTI 是什么？

Speaker 2: 我想说 INFP，但我不太确定。对，我我我不太记得这些字母的意思。对。

Speaker 1: 你之前听过我们的博客没有？

Speaker 2: 我就听到你和小红的那一期的前半部分，我觉得还挺有意思的。

Speaker 1: 好了，今天的节目就是这样。这里是商业访谈录，是一档由语言及世界工作室出品的深度访谈节目。你可以到公众号关注我们的工作室，获取更多的信息。我们的公众号是语言及世界，language is world， 我们希望和你一起从这里探索新的世界。